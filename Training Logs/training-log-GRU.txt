ael@gpu-inst-4:~/Deep-Learning$ python DeepCoNN-GRU.py                            [83/599]
Using TensorFlow backend.
/home/michael/Deep-Learning/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compilet$
me version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime versi$
n 3.6
  return f(*args, **kwds)
  __________________________________________________________________________________________________
  Layer (type)                    Output Shape         Param #     Connected to
  ==================================================================================================
  input_1 (InputLayer)            (None, 243, 50)      0
  __________________________________________________________________________________________________
  input_2 (InputLayer)            (None, 736, 50)      0
  __________________________________________________________________________________________________
  gru_1 (GRU)                     (None, 64)           22080       input_1[0][0]
  __________________________________________________________________________________________________
  gru_2 (GRU)                     (None, 64)           22080       input_2[0][0]
  __________________________________________________________________________________________________
  dense_1 (Dense)                 (None, 64)           4160        gru_1[0][0]
  __________________________________________________________________________________________________
  dense_2 (Dense)                 (None, 64)           4160        gru_2[0][0]
  __________________________________________________________________________________________________
  concatenate_1 (Concatenate)     (None, 128)          0           dense_1[0][0]
                                                                   dense_2[0][0]
  __________________________________________________________________________________________________
  dense_3 (Dense)                 (None, 1)            129         concatenate_1[0][0]
  __________________________________________________________________________________________________
  dot_1 (Dot)                     (None, 1)            0           dense_1[0][0]
                                                                                                                                    dense_2[0][0]
  __________________________________________________________________________________________________
  add_1 (Add)                     (None, 1)            0           dense_3[0][0]
                                                                                                                                                                                                     dot_1[0][0]
  ==================================================================================================
  Total params: 52,609
  Trainable params: 52,609
  Non-trainable params: 0
  __________________________________________________________________________________________________
  None
  Train on 24823 samples, validate on 1307 samples
  2017-12-15 02:10:10.833004: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports in
  structions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
  Epoch 1/50
  24823/24823 [==============================] - 307s 12ms/step - loss: 1.4857 - val_loss: 1.4767
  Epoch 2/50
  24823/24823 [==============================] - 309s 12ms/step - loss: 1.0699 - val_loss: 1.4183
  Epoch 3/50
  24823/24823 [==============================] - 307s 12ms/step - loss: 1.0206 - val_loss: 1.4393
  Epoch 4/50
  24823/24823 [==============================] - 306s 12ms/step - loss: 0.9861 - val_loss: 1.3545
  Epoch 5/50
  24823/24823 [==============================] - 304s 12ms/step - loss: 0.9539 - val_loss: 1.3624
  Epoch 6/50
  24823/24823 [==============================] - 304s 12ms/step - loss: 0.9228 - val_loss: 1.3880
  Epoch 7/50
  24823/24823 [==============================] - 304s 12ms/step - loss: 0.8984 - val_loss: 1.3513
  Epoch 8/50
  24823/24823 [==============================] - 305s 12ms/step - loss: 0.8634 - val_loss: 1.3849
  Epoch 9/50
  24823/24823 [==============================] - 306s 12ms/step - loss: 0.8318 - val_loss: 1.4025
  Epoch 10/50
  24823/24823 [==============================] - 304s 12ms/step - loss: 0.8003 - val_loss: 1.4062
  Epoch 11/50
  24823/24823 [==============================] - 303s 12ms/step - loss: 0.7702 - val_loss: 1.4403
  Epoch 12/50
  24823/24823 [==============================] - 301s 12ms/step - loss: 0.7393 - val_loss: 1.4589
  Epoch 13/50
  24823/24823 [==============================] - 305s 12ms/step - loss: 0.7050 - val_loss: 1.4718
  Epoch 14/50
  24823/24823 [==============================] - 306s 12ms/step - loss: 0.6733 - val_loss: 1.4540
  Epoch 15/50
  24823/24823 [==============================] - 306s 12ms/step - loss: 0.6452 - val_loss: 1.4819
  Epoch 16/50
  24823/24823 [==============================] - 306s 12ms/step - loss: 0.6186 - val_loss: 1.4805
  Epoch 17/50
  24823/24823 [==============================] - 306s 12ms/step - loss: 0.5914 - val_loss: 1.4953
  Epoch 18/50
  24823/24823 [==============================] - 304s 12ms/step - loss: 0.5692 - val_loss: 1.5778
  Epoch 19/50
  24823/24823 [==============================] - 308s 12ms/step - loss: 0.5477 - val_loss: 1.5361
  Epoch 20/50
  24823/24823 [==============================] - 308s 12ms/step - loss: 0.5269 - val_loss: 1.5325
  Epoch 21/50
  24823/24823 [==============================] - 308s 12ms/step - loss: 0.5068 - val_loss: 1.5898
  Epoch 22/50
  24823/24823 [==============================] - 307s 12ms/step - loss: 0.4925 - val_loss: 1.6136
  Epoch 23/50
  24823/24823 [==============================] - 302s 12ms/step - loss: 0.4730 - val_loss: 1.6275
  Epoch 24/50
  24823/24823 [==============================] - 302s 12ms/step - loss: 0.4636 - val_loss: 1.5844
  Epoch 25/50
  24823/24823 [==============================] - 300s 12ms/step - loss: 0.4888 - val_loss: 1.6900
  Epoch 26/50
  24823/24823 [==============================] - 300s 12ms/step - loss: 0.4547 - val_loss: 1.5865
  Epoch 27/50
  24823/24823 [==============================] - 301s 12ms/step - loss: 0.4200 - val_loss: 1.6341
  Epoch 28/50
  24823/24823 [==============================] - 300s 12ms/step - loss: 0.4061 - val_loss: 1.6511
  Epoch 29/50
  24823/24823 [==============================] - 299s 12ms/step - loss: 0.4019 - val_loss: 1.6923
  Epoch 30/50
  24823/24823 [==============================] - 298s 12ms/step - loss: 0.3971 - val_loss: 1.6519
  Epoch 31/50
  24823/24823 [==============================] - 298s 12ms/step - loss: 0.3867 - val_loss: 1.7206
  Epoch 32/50
  24823/24823 [==============================] - 297s 12ms/step - loss: 0.3856 - val_loss: 1.6747
  Epoch 33/50
  24823/24823 [==============================] - 298s 12ms/step - loss: 0.4548 - val_loss: 1.6837
  Epoch 34/50
  24823/24823 [==============================] - 295s 12ms/step - loss: 0.3660 - val_loss: 1.7045
  Epoch 35/50
  24823/24823 [==============================] - 290s 12ms/step - loss: 0.3525 - val_loss: 1.7211
  Epoch 36/50
  24823/24823 [==============================] - 297s 12ms/step - loss: 0.3481 - val_loss: 1.6877
  Epoch 37/50
  24823/24823 [==============================] - 298s 12ms/step - loss: 0.3500 - val_loss: 1.7723
  Epoch 38/50
  24823/24823 [==============================] - 300s 12ms/step - loss: 0.3452 - val_loss: 1.7591
  Epoch 39/50
  24823/24823 [==============================] - 297s 12ms/step - loss: 0.3389 - val_loss: 1.7853
  Epoch 40/50
  24823/24823 [==============================] - 298s 12ms/step - loss: 0.3379 - val_loss: 1.7842
  Epoch 41/50
  24823/24823 [==============================] - 297s 12ms/step - loss: 0.3315 - val_loss: 1.7776
  Epoch 42/50
  24823/24823 [==============================] - 299s 12ms/step - loss: 0.3382 - val_loss: 1.7839
  Epoch 43/50
  24823/24823 [==============================] - 299s 12ms/step - loss: 0.3287 - val_loss: 1.7473
  Epoch 44/50
  24823/24823 [==============================] - 300s 12ms/step - loss: 0.3192 - val_loss: 1.8062
  Epoch 45/50
  24823/24823 [==============================] - 299s 12ms/step - loss: 0.3254 - val_loss: 1.7184
  Epoch 46/50
  24823/24823 [==============================] - 299s 12ms/step - loss: 0.4485 - val_loss: 1.7975
  Epoch 47/50
  24823/24823 [==============================] - 299s 12ms/step - loss: 0.3320 - val_loss: 1.7599
  Epoch 48/50
  24823/24823 [==============================] - 299s 12ms/step - loss: 0.3145 - val_loss: 1.8443
  Epoch 49/50
  24823/24823 [==============================] - 298s 12ms/step - loss: 0.2976 - val_loss: 1.8363
  Epoch 50/50
  24823/24823 [==============================] - 298s 12ms/step - loss: 0.2975 - val_loss: 1.8234
  average test error (not the squared loss): 1.04578825772

