(venv) michael@gpu-inst-4:~/Deep-Learning$ python DeepCoNN-LSTM-Dropout-100D.py
Using TensorFlow backend.
/home/michael/Deep-Learning/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compileti
me version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime versio
n 3.6
  return f(*args, **kwds)
  __________________________________________________________________________________________________
  Layer (type)                    Output Shape         Param #     Connected to
  ==================================================================================================
  input_1 (InputLayer)            (None, 243, 100)     0
  __________________________________________________________________________________________________
  input_2 (InputLayer)            (None, 736, 100)     0
  __________________________________________________________________________________________________
  lstm_1 (LSTM)                   (None, 64)           42240       input_1[0][0]
  __________________________________________________________________________________________________
  lstm_2 (LSTM)                   (None, 64)           42240       input_2[0][0]
  __________________________________________________________________________________________________
  dropout_1 (Dropout)             (None, 64)           0           lstm_1[0][0]
  __________________________________________________________________________________________________
  dropout_2 (Dropout)             (None, 64)           0           lstm_2[0][0]
  __________________________________________________________________________________________________
  dense_1 (Dense)                 (None, 64)           4160        dropout_1[0][0]
  __________________________________________________________________________________________________
  dense_2 (Dense)                 (None, 64)           4160        dropout_2[0][0]
  __________________________________________________________________________________________________
  concatenate_1 (Concatenate)     (None, 128)          0           dense_1[0][0]
                                                                   dense_2[0][0]
  __________________________________________________________________________________________________
  dense_3 (Dense)                 (None, 1)            129         concatenate_1[0][0]
  __________________________________________________________________________________________________
  dot_1 (Dot)                     (None, 1)            0           dense_1[0][0]
                                                                   dense_2[0][0]
  __________________________________________________________________________________________________
  add_1 (Add)                     (None, 1)            0           dense_3[0][0]
  dot_1[0][0]
  ==================================================================================================
  Total params: 92,929
  Trainable params: 92,929
  Non-trainable params: 0
  __________________________________________________________________________________________________
  None
  Train on 25278 samples, validate on 1331 samples
  2017-12-15 06:44:43.503576: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports in
  structions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
  Epoch 1/50
  25278/25278 [==============================] - 391s 15ms/step - loss: 1.4360 - val_loss: 1.6388
  Epoch 2/50
  25278/25278 [==============================] - 391s 15ms/step - loss: 1.1618 - val_loss: 1.5181
  Epoch 3/50
  25278/25278 [==============================] - 392s 16ms/step - loss: 1.1166 - val_loss: 1.4885
  Epoch 4/50
  25278/25278 [==============================] - 393s 16ms/step - loss: 1.0852 - val_loss: 1.4922
  Epoch 5/50
  25278/25278 [==============================] - 393s 16ms/step - loss: 1.0422 - val_loss: 1.4658
  Epoch 6/50
  25278/25278 [==============================] - 389s 15ms/step - loss: 1.0106 - val_loss: 1.4333
  Epoch 7/50
  25278/25278 [==============================] - 391s 15ms/step - loss: 0.9910 - val_loss: 1.4256
  Epoch 8/50
  25278/25278 [==============================] - 390s 15ms/step - loss: 0.9544 - val_loss: 1.4211
  Epoch 9/50
  25278/25278 [==============================] - 389s 15ms/step - loss: 0.9189 - val_loss: 1.4321
  Epoch 10/50
  25278/25278 [==============================] - 383s 15ms/step - loss: 0.8850 - val_loss: 1.4306
  Epoch 11/50
  25278/25278 [==============================] - 383s 15ms/step - loss: 0.8898 - val_loss: 1.4095
  Epoch 12/50
  25278/25278 [==============================] - 383s 15ms/step - loss: 0.8402 - val_loss: 1.4657
  Epoch 13/50
  25278/25278 [==============================] - 384s 15ms/step - loss: 0.8202 - val_loss: 1.4250
  Epoch 14/50
  25278/25278 [==============================] - 377s 15ms/step - loss: 0.8036 - val_loss: 1.4882
  Epoch 15/50
  25278/25278 [==============================] - 379s 15ms/step - loss: 0.7767 - val_loss: 1.4644
  Epoch 16/50
  25278/25278 [==============================] - 384s 15ms/step - loss: 0.7623 - val_loss: 1.5084
  Epoch 17/50
  25278/25278 [==============================] - 384s 15ms/step - loss: 0.8423 - val_loss: 1.5734
  Epoch 18/50
  25278/25278 [==============================] - 384s 15ms/step - loss: 0.8106 - val_loss: 1.5681
  Epoch 19/50
  25278/25278 [==============================] - 384s 15ms/step - loss: 0.7489 - val_loss: 1.5674
  Epoch 20/50
  25278/25278 [==============================] - 385s 15ms/step - loss: 0.7237 - val_loss: 1.5501
  Epoch 21/50
  25278/25278 [==============================] - 385s 15ms/step - loss: 0.7080 - val_loss: 1.5894
  Epoch 22/50
  25278/25278 [==============================] - 385s 15ms/step - loss: 0.6862 - val_loss: 1.5531
  Epoch 23/50
  25278/25278 [==============================] - 385s 15ms/step - loss: 0.6650 - val_loss: 1.5328
  Epoch 24/50
  25278/25278 [==============================] - 385s 15ms/step - loss: 0.7631 - val_loss: 1.6768
  Epoch 25/50
  25278/25278 [==============================] - 386s 15ms/step - loss: 0.6910 - val_loss: 1.6066
  Epoch 26/50
  25278/25278 [==============================] - 385s 15ms/step - loss: 0.6377 - val_loss: 1.6344
  Epoch 27/50
  25278/25278 [==============================] - 387s 15ms/step - loss: 0.6047 - val_loss: 1.6178
  Epoch 28/50
  25278/25278 [==============================] - 387s 15ms/step - loss: 0.5804 - val_loss: 1.6207
  Epoch 29/50
  25278/25278 [==============================] - 386s 15ms/step - loss: 0.5713 - val_loss: 1.6145
  Epoch 30/50
  25278/25278 [==============================] - 386s 15ms/step - loss: 0.5585 - val_loss: 1.5882
  Epoch 31/50
  25278/25278 [==============================] - 386s 15ms/step - loss: 0.5401 - val_loss: 1.7032
  Epoch 32/50
  25278/25278 [==============================] - 386s 15ms/step - loss: 0.5286 - val_loss: 1.6030
  Epoch 33/50
  25278/25278 [==============================] - 385s 15ms/step - loss: 0.5119 - val_loss: 1.6909
  Epoch 34/50
  25278/25278 [==============================] - 385s 15ms/step - loss: 0.4972 - val_loss: 1.6858
  Epoch 35/50
  25278/25278 [==============================] - 384s 15ms/step - loss: 0.4810 - val_loss: 1.7117
  Epoch 36/50
  25278/25278 [==============================] - 385s 15ms/step - loss: 0.4617 - val_loss: 1.7169
  Epoch 37/50
  25278/25278 [==============================] - 384s 15ms/step - loss: 0.4508 - val_loss: 1.7260
  Epoch 38/50
  25278/25278 [==============================] - 383s 15ms/step - loss: 0.4291 - val_loss: 1.6916
  Epoch 39/50
  25278/25278 [==============================] - 384s 15ms/step - loss: 0.4189 - val_loss: 1.7057
  Epoch 40/50
  25278/25278 [==============================] - 384s 15ms/step - loss: 0.4090 - val_loss: 1.7041
  Epoch 41/50
  25278/25278 [==============================] - 384s 15ms/step - loss: 0.3938 - val_loss: 1.6839
  Epoch 42/50
  25278/25278 [==============================] - 383s 15ms/step - loss: 0.3854 - val_loss: 1.8217
  Epoch 43/50
  25278/25278 [==============================] - 382s 15ms/step - loss: 0.3773 - val_loss: 1.6676
  Epoch 44/50
  25278/25278 [==============================] - 383s 15ms/step - loss: 0.3670 - val_loss: 1.7718
  Epoch 45/50
  25278/25278 [==============================] - 386s 15ms/step - loss: 0.3549 - val_loss: 1.7368
  Epoch 46/50
  25278/25278 [==============================] - 385s 15ms/step - loss: 0.3499 - val_loss: 1.7322
  Epoch 47/50
  25278/25278 [==============================] - 383s 15ms/step - loss: 0.3377 - val_loss: 1.6823
  Epoch 48/50
  25278/25278 [==============================] - 385s 15ms/step - loss: 0.3263 - val_loss: 1.7091
  Epoch 49/50
  25278/25278 [==============================] - 385s 15ms/step - loss: 0.3224 - val_loss: 1.7671
  Epoch 50/50
  25278/25278 [==============================] - 383s 15ms/step - loss: 0.3165 - val_loss: 1.7886
  average test error (not the squared loss): 1.11186751019

