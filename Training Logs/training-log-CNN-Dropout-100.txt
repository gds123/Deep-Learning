/home/michael/Deep-Learning/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compileti
me version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime versio
n 3.6
  return f(*args, **kwds)
  __________________________________________________________________________________________________
  Layer (type)                    Output Shape         Param #     Connected to
  ==================================================================================================
  input_1 (InputLayer)            (None, 243, 100)     0
  __________________________________________________________________________________________________
  input_2 (InputLayer)            (None, 736, 100)     0
  __________________________________________________________________________________________________
  conv1d_1 (Conv1D)               (None, 234, 2)       2002        input_1[0][0]
  __________________________________________________________________________________________________
  conv1d_2 (Conv1D)               (None, 727, 2)       2002        input_2[0][0]
  __________________________________________________________________________________________________
  dropout_1 (Dropout)             (None, 234, 2)       0           conv1d_1[0][0]
  __________________________________________________________________________________________________
  dropout_2 (Dropout)             (None, 727, 2)       0           conv1d_2[0][0]
  __________________________________________________________________________________________________
  max_pooling1d_1 (MaxPooling1D)  (None, 117, 2)       0           dropout_1[0][0]
  __________________________________________________________________________________________________
  max_pooling1d_2 (MaxPooling1D)  (None, 363, 2)       0           dropout_2[0][0]
  __________________________________________________________________________________________________
  flatten_1 (Flatten)             (None, 234)          0           max_pooling1d_1[0][0]
  __________________________________________________________________________________________________
  flatten_2 (Flatten)             (None, 726)          0           max_pooling1d_2[0][0]
  __________________________________________________________________________________________________
  dense_1 (Dense)                 (None, 64)           15040       flatten_1[0][0]
  __________________________________________________________________________________________________
  dense_2 (Dense)                 (None, 64)           46528       flatten_2[0][0]
  __________________________________________________________________________________________________
  concatenate_1 (Concatenate)     (None, 128)          0           dense_1[0][0]
dense_2[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            129         concatenate_1[0][0]
__________________________________________________________________________________________________
dot_1 (Dot)                     (None, 1)            0           dense_1[0][0]
dense_2[0][0]
__________________________________________________________________________________________________
add_1 (Add)                     (None, 1)            0           dense_3[0][0]
dot_1[0][0]
==================================================================================================
Total params: 65,701
Trainable params: 65,701
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 25655 samples, validate on 1351 samples
2017-12-14 23:02:07.806559: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports i$
structions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
Epoch 1/50
25655/25655 [==============================] - 57s 2ms/step - loss: 1.3510 - val_loss: 1.5521
Epoch 2/50
25655/25655 [==============================] - 58s 2ms/step - loss: 1.0818 - val_loss: 1.4720
Epoch 3/50
25655/25655 [==============================] - 58s 2ms/step - loss: 1.0287 - val_loss: 1.4595
Epoch 4/50
25655/25655 [==============================] - 58s 2ms/step - loss: 1.0171 - val_loss: 1.5006
Epoch 5/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.9902 - val_loss: 1.6596
Epoch 6/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.9686 - val_loss: 1.5581
Epoch 7/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.9473 - val_loss: 1.6029
Epoch 8/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.9302 - val_loss: 1.4629
Epoch 9/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.9267 - val_loss: 1.6762
Epoch 10/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.8972 - val_loss: 1.4708
Epoch 11/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.9346 - val_loss: 1.4377
Epoch 12/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.9123 - val_loss: 1.4593
Epoch 13/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.8817 - val_loss: 1.4076
Epoch 14/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.8672 - val_loss: 1.4645
Epoch 15/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.8741 - val_loss: 1.4410
Epoch 16/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.8378 - val_loss: 1.4400
Epoch 17/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.8157 - val_loss: 1.4306
Epoch 18/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.9363 - val_loss: 1.6043
Epoch 19/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.8294 - val_loss: 1.4602
Epoch 20/50
25655/25655 [==============================] - 56s 2ms/step - loss: 0.7874 - val_loss: 1.4663
Epoch 21/50
25655/25655 [==============================] - 56s 2ms/step - loss: 0.7686 - val_loss: 1.4675
Epoch 22/50
25655/25655 [==============================] - 56s 2ms/step - loss: 0.7592 - val_loss: 1.5895
Epoch 23/50
25655/25655 [==============================] - 56s 2ms/step - loss: 0.7737 - val_loss: 1.4407
Epoch 23/50
25655/25655 [==============================] - 56s 2ms/step - loss: 0.7737 - val_loss: 1.4407
Epoch 24/50
25655/25655 [==============================] - 56s 2ms/step - loss: 0.8051 - val_loss: 1.6132
Epoch 25/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.7413 - val_loss: 1.4848
Epoch 26/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.7143 - val_loss: 1.6502
Epoch 27/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.7794 - val_loss: 1.5896
Epoch 28/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.7272 - val_loss: 1.5353
Epoch 29/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.7003 - val_loss: 1.5617
Epoch 30/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.8309 - val_loss: 1.5302
Epoch 31/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.7504 - val_loss: 1.5889
Epoch 32/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.6840 - val_loss: 1.5256
Epoch 33/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.6735 - val_loss: 1.5381
Epoch 34/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.6672 - val_loss: 1.5273
Epoch 35/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.6525 - val_loss: 1.6799
Epoch 36/50
25655/25655 [==============================] - 57s 2ms/step - loss: 0.6605 - val_loss: 1.5933
Epoch 37/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.6640 - val_loss: 1.6098
Epoch 38/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.7917 - val_loss: 1.6921
Epoch 39/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.8532 - val_loss: 1.6068
Epoch 40/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.6897 - val_loss: 1.5624
Epoch 41/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.6839 - val_loss: 1.6093
Epoch 42/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.6461 - val_loss: 1.6008
Epoch 43/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.6206 - val_loss: 1.5687
Epoch 44/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.6419 - val_loss: 1.6463
Epoch 45/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.6144 - val_loss: 1.6041
Epoch 46/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.6721 - val_loss: 1.5720
Epoch 47/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.6138 - val_loss: 1.6536
Epoch 48/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.6250 - val_loss: 1.6471
Epoch 49/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.6126 - val_loss: 1.7902
Epoch 50/50
25655/25655 [==============================] - 58s 2ms/step - loss: 0.5957 - val_loss: 1.6508
average test error (not the squared loss): 1.03720052967
