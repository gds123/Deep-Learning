(venv) michael@gpu-inst-4:~/Deep-Learning$ python DeepCoNN-CNN-Dropout.py
Using TensorFlow backend.
/home/michael/Deep-Learning/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compileti
me version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime versio
n 3.6
  return f(*args, **kwds)
  __________________________________________________________________________________________________
  Layer (type)                    Output Shape         Param #     Connected to
  ==================================================================================================
  input_1 (InputLayer)            (None, 243, 50)      0
  __________________________________________________________________________________________________
  input_2 (InputLayer)            (None, 736, 50)      0
  __________________________________________________________________________________________________
  conv1d_1 (Conv1D)               (None, 234, 2)       1002        input_1[0][0]
  __________________________________________________________________________________________________
  conv1d_2 (Conv1D)               (None, 727, 2)       1002        input_2[0][0]
  __________________________________________________________________________________________________
  dropout_1 (Dropout)             (None, 234, 2)       0           conv1d_1[0][0]
  __________________________________________________________________________________________________
  dropout_2 (Dropout)             (None, 727, 2)       0           conv1d_2[0][0]
  __________________________________________________________________________________________________
  max_pooling1d_1 (MaxPooling1D)  (None, 117, 2)       0           dropout_1[0][0]
  __________________________________________________________________________________________________
  max_pooling1d_2 (MaxPooling1D)  (None, 363, 2)       0           dropout_2[0][0]
  __________________________________________________________________________________________________
  flatten_1 (Flatten)             (None, 234)          0           max_pooling1d_1[0][0]
  __________________________________________________________________________________________________
  flatten_2 (Flatten)             (None, 726)          0           max_pooling1d_2[0][0]
  __________________________________________________________________________________________________
  dense_1 (Dense)                 (None, 64)           15040       flatten_1[0][0]
  __________________________________________________________________________________________________
  dense_2 (Dense)                 (None, 64)           46528       flatten_2[0][0]
  __________________________________________________________________________________________________
  concatenate_1 (Concatenate)     (None, 128)          0           dense_1[0][0]
  dense_2[0][0]
  __________________________________________________________________________________________________
  dense_3 (Dense)                 (None, 1)            129         concatenate_1[0][0]
  __________________________________________________________________________________________________
  dot_1 (Dot)                     (None, 1)            0           dense_1[0][0]
  dense_2[0][0]
  __________________________________________________________________________________________________
  add_1 (Add)                     (None, 1)            0           dense_3[0][0]
  dot_1[0][0]
rams: 63,701
Trainable params: 63,701
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 27352 samples, validate on 1440 samples
2017-12-15 00:22:27.511217: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports in
structions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
Epoch 1/50
27352/27352 [==============================] - 43s 2ms/step - loss: 1.3603 - val_loss: 1.5187
Epoch 2/50
27352/27352 [==============================] - 42s 2ms/step - loss: 1.0458 - val_loss: 1.4663
Epoch 3/50
27352/27352 [==============================] - 41s 2ms/step - loss: 1.0052 - val_loss: 1.4065
Epoch 4/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.9868 - val_loss: 1.4116
Epoch 5/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.9700 - val_loss: 1.4414
Epoch 6/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.9471 - val_loss: 1.5890
Epoch 7/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.9380 - val_loss: 1.4003
Epoch 8/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.9269 - val_loss: 1.3741
Epoch 9/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.8933 - val_loss: 1.3933
Epoch 10/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.8716 - val_loss: 1.4288
Epoch 11/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.8571 - val_loss: 1.4083
Epoch 12/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.8366 - val_loss: 1.4283
Epoch 13/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.8267 - val_loss: 1.4944
Epoch 14/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.8433 - val_loss: 1.5704
Epoch 15/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.7962 - val_loss: 1.4258
Epoch 16/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.8022 - val_loss: 1.5637
Epoch 17/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.7575 - val_loss: 1.4940
Epoch 18/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.7484 - val_loss: 1.4879
Epoch 19/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.8901 - val_loss: 1.4837
Epoch 20/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.7913 - val_loss: 1.4704
Epoch 21/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.7251 - val_loss: 1.4914
Epoch 22/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.7075 - val_loss: 1.4748
Epoch 23/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.7004 - val_loss: 1.5852
Epoch 24/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6863 - val_loss: 1.5420
Epoch 25/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6724 - val_loss: 1.4630
Epoch 26/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.7172 - val_loss: 1.5227
Epoch 27/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6648 - val_loss: 1.4591
Epoch 28/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6702 - val_loss: 1.4582
Epoch 29/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6538 - val_loss: 1.6124
Epoch 30/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6442 - val_loss: 1.5213
Epoch 31/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.9046 - val_loss: 1.5070
Epoch 32/50
27352/27352 [==============================] - 39s 1ms/step - loss: 0.8091 - val_loss: 1.4864
Epoch 33/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.7616 - val_loss: 1.5260
Epoch 34/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.7046 - val_loss: 1.5229
Epoch 35/50
27352/27352 [==============================] - 39s 1ms/step - loss: 0.6430 - val_loss: 1.5923
Epoch 36/50
27352/27352 [==============================] - 39s 1ms/step - loss: 0.6669 - val_loss: 1.5254
Epoch 37/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6402 - val_loss: 1.6740
Epoch 38/50
27352/27352 [==============================] - 39s 1ms/step - loss: 0.6098 - val_loss: 1.5366
Epoch 39/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6168 - val_loss: 1.5851
Epoch 40/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6048 - val_loss: 1.6834
Epoch 41/50
27352/27352 [==============================] - 39s 1ms/step - loss: 0.5984 - val_loss: 1.5801
Epoch 42/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6004 - val_loss: 1.6560
Epoch 43/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.5961 - val_loss: 1.5495
Epoch 44/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.5936 - val_loss: 1.5483
Epoch 45/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6050 - val_loss: 1.6608
Epoch 46/50
27352/27352 [==============================] - 39s 1ms/step - loss: 0.6290 - val_loss: 1.5900
Epoch 47/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6050 - val_loss: 1.4394
Epoch 48/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.6677 - val_loss: 1.7030
Epoch 49/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.5915 - val_loss: 1.5777
Epoch 50/50
27352/27352 [==============================] - 40s 1ms/step - loss: 0.5693 - val_loss: 1.5276
average test error (not the squared loss): 0.970476221269
(venv) michael@gpu-inst-4:~/Deep-Learning$

