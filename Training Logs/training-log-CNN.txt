/home/michael/Deep-Learning/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compileti
me version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime versio
n 3.6
  return f(*args, **kwds)
  __________________________________________________________________________________________________
  Layer (type)                    Output Shape         Param #     Connected to
  ==================================================================================================
  input_1 (InputLayer)            (None, 243, 50)      0
  __________________________________________________________________________________________________
  input_2 (InputLayer)            (None, 736, 50)      0
  __________________________________________________________________________________________________
  conv1d_1 (Conv1D)               (None, 234, 2)       1002        input_1[0][0]
  __________________________________________________________________________________________________
  conv1d_2 (Conv1D)               (None, 727, 2)       1002        input_2[0][0]
  __________________________________________________________________________________________________
  max_pooling1d_1 (MaxPooling1D)  (None, 117, 2)       0           conv1d_1[0][0]
  __________________________________________________________________________________________________
  max_pooling1d_2 (MaxPooling1D)  (None, 363, 2)       0           conv1d_2[0][0]
  __________________________________________________________________________________________________
  flatten_1 (Flatten)             (None, 234)          0           max_pooling1d_1[0][0]
  __________________________________________________________________________________________________
  flatten_2 (Flatten)             (None, 726)          0           max_pooling1d_2[0][0]
  __________________________________________________________________________________________________
  dense_1 (Dense)                 (None, 64)           15040       flatten_1[0][0]
  __________________________________________________________________________________________________
  dense_2 (Dense)                 (None, 64)           46528       flatten_2[0][0]
  __________________________________________________________________________________________________
  concatenate_1 (Concatenate)     (None, 128)          0           dense_1[0][0]
dense_2[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            129         concatenate_1[0][0]
__________________________________________________________________________________________________
dot_1 (Dot)                     (None, 1)            0           dense_1[0][0]
dense_2[0][0]
__________________________________________________________________________________________________
add_1 (Add)                     (None, 1)            0           dense_3[0][0]
dot_1[0][0]
==================================================================================================
Total params: 63,701
Trainable params: 63,701
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 23782 samples, validate on 1252 samples
2017-12-14 23:21:34.829134: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports in
structions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
Epoch 1/50
23782/23782 [==============================] - 35s 1ms/step - loss: 1.3139 - val_loss: 1.7606
Epoch 2/50
23782/23782 [==============================] - 34s 1ms/step - loss: 1.0798 - val_loss: 1.4450
Epoch 3/50
23782/23782 [==============================] - 34s 1ms/step - loss: 1.0374 - val_loss: 1.6541
Epoch 4/50
23782/23782 [==============================] - 34s 1ms/step - loss: 1.0119 - val_loss: 1.4272
Epoch 5/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.9757 - val_loss: 1.4105
Epoch 6/50
23782/23782 [==============================] - 35s 1ms/step - loss: 0.9494 - val_loss: 1.6114
Epoch 7/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.9359 - val_loss: 1.4196
Epoch 8/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.8983 - val_loss: 1.4823
Epoch 9/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.9673 - val_loss: 1.4341
Epoch 10/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.8972 - val_loss: 1.4285
Epoch 11/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.8271 - val_loss: 1.5975
Epoch 12/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.7965 - val_loss: 1.4990
Epoch 13/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.7748 - val_loss: 1.5420
Epoch 14/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.7620 - val_loss: 1.4955
Epoch 15/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.7217 - val_loss: 1.4926
Epoch 16/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.7015 - val_loss: 1.5638
Epoch 17/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.6586 - val_loss: 1.5266
Epoch 18/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.6332 - val_loss: 1.6676
Epoch 19/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.6876 - val_loss: 1.4144
Epoch 20/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.6164 - val_loss: 1.5623
Epoch 21/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.5730 - val_loss: 1.6124
Epoch 22/50
23782/23782 [==============================] - 35s 1ms/step - loss: 0.5718 - val_loss: 1.6137
Epoch 23/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.5452 - val_loss: 1.5896
Epoch 24/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.5278 - val_loss: 1.6594
Epoch 25/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.5516 - val_loss: 1.6054
Epoch 26/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4999 - val_loss: 1.6105
Epoch 27/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4863 - val_loss: 1.6508
Epoch 28/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4748 - val_loss: 1.8710
Epoch 29/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4812 - val_loss: 1.7739
Epoch 30/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4924 - val_loss: 1.7914
Epoch 31/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4503 - val_loss: 1.8325
Epoch 32/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4988 - val_loss: 1.9174
Epoch 33/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4400 - val_loss: 1.7414
Epoch 34/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4227 - val_loss: 1.8453
Epoch 35/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4302 - val_loss: 1.8830
Epoch 36/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4203 - val_loss: 1.8486
Epoch 37/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4095 - val_loss: 2.0495
Epoch 38/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.3969 - val_loss: 2.0457
Epoch 39/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.3985 - val_loss: 1.9174
Epoch 40/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4007 - val_loss: 1.8884
Epoch 41/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.5166 - val_loss: 1.8845
Epoch 42/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4119 - val_loss: 1.8806
Epoch 43/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.3789 - val_loss: 1.8464
Epoch 44/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.3631 - val_loss: 1.9653
Epoch 45/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.3631 - val_loss: 1.7988
Epoch 46/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.4313 - val_loss: 2.0570
Epoch 47/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.3579 - val_loss: 1.9784
Epoch 48/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.3482 - val_loss: 2.0081
Epoch 49/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.3588 - val_loss: 1.8787
Epoch 50/50
23782/23782 [==============================] - 34s 1ms/step - loss: 0.3485 - val_loss: 1.9527
average test error (not the squared loss): 0.838151431041
