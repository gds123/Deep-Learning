michael@gpu-inst-3:~/Deep-Learning$ python DeepCoNN-LSTM-100D.py                             [83/147]
Using TensorFlow backend.
/home/michael/Deep-Learning/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compilet$
me version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime versi$
n 3.6
  return f(*args, **kwds)
  __________________________________________________________________________________________________
  Layer (type)                    Output Shape         Param #     Connected to
  ==================================================================================================
  input_1 (InputLayer)            (None, 243, 100)     0
  __________________________________________________________________________________________________
  input_2 (InputLayer)            (None, 736, 100)     0
  __________________________________________________________________________________________________
  lstm_1 (LSTM)                   (None, 64)           42240       input_1[0][0]
  __________________________________________________________________________________________________
  lstm_2 (LSTM)                   (None, 64)           42240       input_2[0][0]
  __________________________________________________________________________________________________
  dense_1 (Dense)                 (None, 64)           4160        lstm_1[0][0]
  __________________________________________________________________________________________________
  dense_2 (Dense)                 (None, 64)           4160        lstm_2[0][0]
  __________________________________________________________________________________________________
  concatenate_1 (Concatenate)     (None, 128)          0           dense_1[0][0]
                                                                   dense_2[0][0]
  __________________________________________________________________________________________________
  dense_3 (Dense)                 (None, 1)            129         concatenate_1[0][0]
  __________________________________________________________________________________________________
  dot_1 (Dot)                     (None, 1)            0           dense_1[0][0]
                                                                                                                                    dense_2[0][0]
  __________________________________________________________________________________________________
  add_1 (Add)                     (None, 1)            0           dense_3[0][0]
                                                                                                                                                                                                     dot_1[0][0]
  ==================================================================================================
  Total params: 92,929
  Trainable params: 92,929
  Non-trainable params: 0
  __________________________________________________________________________________________________
  None
  Train on 25021 samples, validate on 1317 samples
  2017-12-15 01:57:52.389144: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports in
  structions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
  Epoch 1/50
  25021/25021 [==============================] - 391s 16ms/step - loss: 1.4557 - val_loss: 1.6286
  Epoch 2/50
  25021/25021 [==============================] - 389s 16ms/step - loss: 1.1917 - val_loss: 1.4802
  Epoch 3/50
  25021/25021 [==============================] - 387s 15ms/step - loss: 1.1120 - val_loss: 1.4377
  Epoch 4/50
  25021/25021 [==============================] - 385s 15ms/step - loss: 1.0549 - val_loss: 1.3892
  Epoch 5/50
  25021/25021 [==============================] - 378s 15ms/step - loss: 1.0232 - val_loss: 1.3756
  Epoch 6/50
  25021/25021 [==============================] - 377s 15ms/step - loss: 0.9910 - val_loss: 1.3822
  Epoch 7/50
  25021/25021 [==============================] - 379s 15ms/step - loss: 0.9660 - val_loss: 1.3485
  Epoch 8/50
  25021/25021 [==============================] - 379s 15ms/step - loss: 0.9300 - val_loss: 1.3579
  Epoch 9/50
  25021/25021 [==============================] - 379s 15ms/step - loss: 0.8926 - val_loss: 1.3616
  Epoch 10/50
  25021/25021 [==============================] - 379s 15ms/step - loss: 0.8583 - val_loss: 1.4297
  Epoch 11/50
  25021/25021 [==============================] - 380s 15ms/step - loss: 0.8264 - val_loss: 1.4171
  Epoch 12/50
  25021/25021 [==============================] - 379s 15ms/step - loss: 0.8214 - val_loss: 1.4596
  Epoch 13/50
  25021/25021 [==============================] - 380s 15ms/step - loss: 0.8182 - val_loss: 1.4121
  Epoch 14/50
  25021/25021 [==============================] - 377s 15ms/step - loss: 0.7643 - val_loss: 1.5342
  Epoch 15/50
  25021/25021 [==============================] - 377s 15ms/step - loss: 0.7387 - val_loss: 1.4444
  Epoch 16/50
  25021/25021 [==============================] - 377s 15ms/step - loss: 0.7015 - val_loss: 1.4660
  Epoch 17/50
  25021/25021 [==============================] - 375s 15ms/step - loss: 0.6645 - val_loss: 1.5026
  Epoch 18/50
  25021/25021 [==============================] - 375s 15ms/step - loss: 0.6375 - val_loss: 1.4615
  Epoch 19/50
  25021/25021 [==============================] - 376s 15ms/step - loss: 0.6074 - val_loss: 1.4942
  Epoch 20/50
  25021/25021 [==============================] - 376s 15ms/step - loss: 0.5820 - val_loss: 1.5092
  Epoch 21/50
  25021/25021 [==============================] - 376s 15ms/step - loss: 0.5560 - val_loss: 1.5195
  Epoch 22/50
  25021/25021 [==============================] - 376s 15ms/step - loss: 0.5311 - val_loss: 1.5838
  Epoch 23/50
  25021/25021 [==============================] - 376s 15ms/step - loss: 0.5112 - val_loss: 1.5438
  Epoch 24/50
  25021/25021 [==============================] - 379s 15ms/step - loss: 0.4879 - val_loss: 1.6083
  Epoch 25/50
  25021/25021 [==============================] - 377s 15ms/step - loss: 0.4693 - val_loss: 1.5832
  Epoch 26/50
  25021/25021 [==============================] - 379s 15ms/step - loss: 0.4457 - val_loss: 1.6328
  Epoch 27/50
  25021/25021 [==============================] - 375s 15ms/step - loss: 0.4305 - val_loss: 1.6055
  Epoch 28/50
  25021/25021 [==============================] - 377s 15ms/step - loss: 0.4133 - val_loss: 1.5815
  Epoch 29/50
  25021/25021 [==============================] - 378s 15ms/step - loss: 0.3980 - val_loss: 1.6780
  Epoch 30/50
  25021/25021 [==============================] - 377s 15ms/step - loss: 0.3813 - val_loss: 1.6632
  Epoch 31/50
  25021/25021 [==============================] - 377s 15ms/step - loss: 0.3668 - val_loss: 1.7625
  Epoch 32/50
  25021/25021 [==============================] - 375s 15ms/step - loss: 0.3640 - val_loss: 1.7213
  Epoch 33/50
  25021/25021 [==============================] - 374s 15ms/step - loss: 0.3454 - val_loss: 1.7314
  Epoch 34/50
  25021/25021 [==============================] - 375s 15ms/step - loss: 0.3261 - val_loss: 1.6907
  Epoch 35/50
  25021/25021 [==============================] - 373s 15ms/step - loss: 0.3236 - val_loss: 1.7306
  Epoch 36/50
  25021/25021 [==============================] - 377s 15ms/step - loss: 0.3141 - val_loss: 1.7571
  Epoch 37/50
  25021/25021 [==============================] - 378s 15ms/step - loss: 0.3036 - val_loss: 1.7365
  Epoch 38/50
  25021/25021 [==============================] - 377s 15ms/step - loss: 0.2956 - val_loss: 1.7330
  Epoch 39/50
  25021/25021 [==============================] - 377s 15ms/step - loss: 0.2871 - val_loss: 1.7701
  Epoch 40/50
  25021/25021 [==============================] - 378s 15ms/step - loss: 0.2780 - val_loss: 1.8336
  Epoch 41/50
  25021/25021 [==============================] - 379s 15ms/step - loss: 0.2888 - val_loss: 1.8094
  Epoch 42/50
  25021/25021 [==============================] - 380s 15ms/step - loss: 0.2601 - val_loss: 1.8546
  Epoch 43/50
  25021/25021 [==============================] - 381s 15ms/step - loss: 0.2538 - val_loss: 1.7962
  Epoch 44/50
  25021/25021 [==============================] - 379s 15ms/step - loss: 0.2487 - val_loss: 1.8934
  Epoch 45/50
  25021/25021 [==============================] - 378s 15ms/step - loss: 0.2456 - val_loss: 1.8207
  Epoch 46/50
  25021/25021 [==============================] - 378s 15ms/step - loss: 0.2389 - val_loss: 1.8403
  Epoch 47/50
  25021/25021 [==============================] - 376s 15ms/step - loss: 0.2319 - val_loss: 1.8275
  Epoch 48/50
  25021/25021 [==============================] - 375s 15ms/step - loss: 0.2246 - val_loss: 1.8398
  Epoch 49/50
  25021/25021 [==============================] - 375s 15ms/step - loss: 0.2210 - val_loss: 1.8324
  Epoch 50/50
  25021/25021 [==============================] - 377s 15ms/step - loss: 0.2173 - val_loss: 1.8337
  average test error (not the squared loss): 0.860508471417
