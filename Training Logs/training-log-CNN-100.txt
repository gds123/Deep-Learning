(venv) michael@gpu-inst-2:~/Deep-Learning$ python DeepCoNN-CNN-100D.py
Using TensorFlow backend.
/home/michael/Deep-Learning/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compileti
me version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime versio
n 3.6
  return f(*args, **kwds)
  __________________________________________________________________________________________________
  Layer (type)                    Output Shape         Param #     Connected to
  ==================================================================================================
  input_1 (InputLayer)            (None, 243, 100)     0
  __________________________________________________________________________________________________
  input_2 (InputLayer)            (None, 736, 100)     0
  __________________________________________________________________________________________________
  conv1d_1 (Conv1D)               (None, 234, 2)       2002        input_1[0][0]
  __________________________________________________________________________________________________
  conv1d_2 (Conv1D)               (None, 727, 2)       2002        input_2[0][0]
  __________________________________________________________________________________________________
  max_pooling1d_1 (MaxPooling1D)  (None, 117, 2)       0           conv1d_1[0][0]
  __________________________________________________________________________________________________
  max_pooling1d_2 (MaxPooling1D)  (None, 363, 2)       0           conv1d_2[0][0]
  __________________________________________________________________________________________________
  flatten_1 (Flatten)             (None, 234)          0           max_pooling1d_1[0][0]
  __________________________________________________________________________________________________
  flatten_2 (Flatten)             (None, 726)          0           max_pooling1d_2[0][0]
  __________________________________________________________________________________________________
  dense_1 (Dense)                 (None, 64)           15040       flatten_1[0][0]
  __________________________________________________________________________________________________
  dense_2 (Dense)                 (None, 64)           46528       flatten_2[0][0]
  __________________________________________________________________________________________________
  concatenate_1 (Concatenate)     (None, 128)          0           dense_1[0][0]
                                                                   dense_2[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            129         concatenate_1[0][0]
__________________________________________________________________________________________________
dot_1 (Dot)                     (None, 1)            0           dense_1[0][0]
dense_2[0][0]
__________________________________________________________________________________________________
add_1 (Add)                     (None, 1)            0           dense_3[0][0]
dot_1[0][0]
==================================================================================================
Total params: 65,701
Trainable params: 65,701
Non-trainable params: 0
__________________________________________________________________________________________________
None
Train on 25259 samples, validate on 1330 samples
2017-12-14 22:45:41.033522: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports i$
structions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
Epoch 1/50
25259/25259 [==============================] - 53s 2ms/step - loss: 1.2424 - val_loss: 1.6759
Epoch 2/50
25259/25259 [==============================] - 53s 2ms/step - loss: 1.0585 - val_loss: 1.6316
Epoch 3/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.9983 - val_loss: 1.6218
Epoch 4/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.9606 - val_loss: 1.6630
Epoch 5/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.9434 - val_loss: 1.6183
Epoch 6/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.9290 - val_loss: 1.6383
Epoch 7/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.9063 - val_loss: 1.6984
Epoch 8/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.8630 - val_loss: 1.6411
Epoch 9/50
25259/25259 [==============================] - 56s 2ms/step - loss: 0.8466 - val_loss: 1.6204
Epoch 10/50
25259/25259 [==============================] - 58s 2ms/step - loss: 0.8313 - val_loss: 1.6593
Epoch 11/50
25259/25259 [==============================] - 58s 2ms/step - loss: 0.7935 - val_loss: 1.6796
Epoch 12/50
25259/25259 [==============================] - 58s 2ms/step - loss: 0.7893 - val_loss: 1.8493
Epoch 13/50
25259/25259 [==============================] - 58s 2ms/step - loss: 0.8560 - val_loss: 1.5448
Epoch 14/50
25259/25259 [==============================] - 56s 2ms/step - loss: 0.8682 - val_loss: 1.8121
Epoch 15/50
25259/25259 [==============================] - 55s 2ms/step - loss: 0.8720 - val_loss: 1.6804
Epoch 16/50
25259/25259 [==============================] - 56s 2ms/step - loss: 0.9556 - val_loss: 1.5614
Epoch 17/50
25259/25259 [==============================] - 55s 2ms/step - loss: 0.8095 - val_loss: 1.7446
Epoch 18/50
25259/25259 [==============================] - 54s 2ms/step - loss: 0.7276 - val_loss: 1.6705
Epoch 19/50
25259/25259 [==============================] - 54s 2ms/step - loss: 0.8748 - val_loss: 1.8425
Epoch 20/50
25259/25259 [==============================] - 54s 2ms/step - loss: 0.8818 - val_loss: 1.8147
Epoch 21/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.8146 - val_loss: 1.8759
Epoch 22/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.7701 - val_loss: 1.9186
Epoch 23/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.7513 - val_loss: 1.8756
Epoch 24/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.7280 - val_loss: 1.8807
Epoch 25/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.6887 - val_loss: 1.9031
Epoch 26/50
25259/25259 [==============================] - 52s 2ms/step - loss: 0.6584 - val_loss: 1.9507
Epoch 27/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.7045 - val_loss: 1.8898
Epoch 28/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.6442 - val_loss: 1.8887
Epoch 29/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.6299 - val_loss: 1.9058
Epoch 30/50
25259/25259 [==============================] - 52s 2ms/step - loss: 0.6080 - val_loss: 1.9067
Epoch 31/50
25259/25259 [==============================] - 52s 2ms/step - loss: 0.5945 - val_loss: 1.9561
Epoch 32/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.5935 - val_loss: 1.9753
Epoch 33/50
25259/25259 [==============================] - 53s 2ms/step - loss: 0.5808 - val_loss: 2.1079
Epoch 34/50
25259/25259 [==============================] - 57s 2ms/step - loss: 0.5658 - val_loss: 2.0914
Epoch 35/50
25259/25259 [==============================] - 57s 2ms/step - loss: 0.5625 - val_loss: 2.0386
Epoch 36/50
25259/25259 [==============================] - 57s 2ms/step - loss: 0.8330 - val_loss: 1.8178
Epoch 37/50
25259/25259 [==============================] - 58s 2ms/step - loss: 0.9788 - val_loss: 1.6476
Epoch 38/50
25259/25259 [==============================] - 58s 2ms/step - loss: 0.8638 - val_loss: 1.6067
Epoch 39/50
25259/25259 [==============================] - 57s 2ms/step - loss: 1.4270 - val_loss: 1.8046
Epoch 40/50
25259/25259 [==============================] - 58s 2ms/step - loss: 1.1621 - val_loss: 1.7460
Epoch 41/50
25259/25259 [==============================] - 57s 2ms/step - loss: 1.0314 - val_loss: 1.7322
Epoch 42/50
25259/25259 [==============================] - 57s 2ms/step - loss: 0.9559 - val_loss: 1.8493
Epoch 43/50
25259/25259 [==============================] - 57s 2ms/step - loss: 0.9132 - val_loss: 1.9422
Epoch 44/50
25259/25259 [==============================] - 57s 2ms/step - loss: 0.8578 - val_loss: 1.9716
Epoch 45/50
25259/25259 [==============================] - 58s 2ms/step - loss: 0.8050 - val_loss: 2.0652
Epoch 46/50
25259/25259 [==============================] - 57s 2ms/step - loss: 0.7701 - val_loss: 2.1820
Epoch 47/50
25259/25259 [==============================] - 57s 2ms/step - loss: 0.6289 - val_loss: 2.0892
Epoch 48/50
25259/25259 [==============================] - 58s 2ms/step - loss: 0.5502 - val_loss: 2.2428
Epoch 49/50
25259/25259 [==============================] - 57s 2ms/step - loss: 0.5322 - val_loss: 2.1166
Epoch 50/50
25259/25259 [==============================] - 57s 2ms/step - loss: 0.5111 - val_loss: 2.0812
average test error (not the squared loss): 0.875454982122
