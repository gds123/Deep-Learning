{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/michael/Documents/deep_learning/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import time\n",
    "import scipy.spatial\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def init_embedding_map(fileName):\n",
    "    print(\"initializing embeddings\")\n",
    "    with open(join(\"data\", \"glove.6B\", fileName)) as glove:\n",
    "        return {l[0]: np.asarray(l[1:], dtype=\"float32\") for l in [line.split() for line in glove]}\n",
    "\n",
    "def clean(text):\n",
    "    return text_to_word_sequence(text, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', \n",
    "                                 lower=True, split=\" \")\n",
    "\n",
    "\n",
    "# returns dict with users and movies they rated as repeated rows\n",
    "# cleans review text and add to rawOutput\n",
    "def init_raw_data(input_file):\n",
    "    print(\"initializing raw data\")\n",
    "    rawInputData = []\n",
    "    rawOutputData = []\n",
    "    with open(input_file,\"r\") as f:\n",
    "        for i in f:\n",
    "            line = f.readline()\n",
    "            if len(line) < 4:\n",
    "                break\n",
    "            lineObj = json.loads(line)\n",
    "            user = lineObj[\"reviewerID\"]\n",
    "            item = lineObj[\"asin\"]\n",
    "            rawInputDataObj = {\"user\": user, \"asin\": item}\n",
    "            rawOutputDataObj = clean(lineObj[\"reviewText\"])\n",
    "            rawInputData.append(rawInputDataObj)\n",
    "            rawOutputData.append(rawOutputDataObj)\n",
    "    return rawInputData, rawOutputData\n",
    "\n",
    "# creates dict of usrs w/ all movies rated + movies w/ all user ratings *** \n",
    "def group_data(inputData):\n",
    "    users = {}\n",
    "    items = {}\n",
    "    for datum in inputData:\n",
    "        u = datum[\"user\"]\n",
    "        i = datum[\"asin\"]\n",
    "        users.setdefault(u, []).append(i)\n",
    "        items.setdefault(i, []).append(u)\n",
    "    return users, items\n",
    "\n",
    "def get_set_from_data(key, data):\n",
    "    return set([datum.get(key) for datum in data])\n",
    "\n",
    "def seq_2_matrix(sequence, embedding_map):\n",
    "    return np.array([embedding_map.get(word) for word in sequence if word in embedding_map])\n",
    "\n",
    "def matrix_2_avg(emb_matrix):\n",
    "    return np.mean(emb_matrix, 0)\n",
    "\n",
    "\n",
    "# utils - one hot encodes all data \n",
    "def init_vec_data(rawInputData, rawOutputData, embedding_map):\n",
    "    print('initializing vectorized data')\n",
    "    dictVect = DictVectorizer()\n",
    "    vecInputData = dictVect.fit_transform(rawInputData).toarray()\n",
    "    vecOutputData = [matrix_2_avg(seq_2_matrix(review, embedding_map)) for review in rawOutputData]\n",
    "    return vecInputData, vecOutputData\n",
    "\n",
    "def init_mat_input_data(rawInputData, rawOutputData, embedding_map, save=False):\n",
    "    print('initializing matrix data')\n",
    "    if len(rawInputData) != len(rawOutputData):\n",
    "        raise ValueError(\"Need same size of input and output\")\n",
    "    users = {}\n",
    "    extra_info = {}\n",
    "    items = {}\n",
    "    dictVect = DictVectorizer()\n",
    "    for i in range(len(rawInputData)):\n",
    "        vecOutput = seq_2_matrix(rawOutputData[i], embedding_map)\n",
    "        rawInput = rawInputData[i]\n",
    "        user = rawInput['user']\n",
    "        item = rawInput['asin']\n",
    "        users.setdefault(user, []).append(vecOutput)\n",
    "        items.setdefault(item, []).append(vecOutput)\n",
    "        \n",
    "    matUserInputData = []\n",
    "    matItemInputData = []\n",
    "    users = {k: np.vstack(v) for k, v in users.items()}\n",
    "    items = {k: np.vstack(v) for k, v in items.items()}\n",
    "    extra_info['user_seq_sizes'] = [m.shape[0] for m in users.values()]\n",
    "    extra_info['item_seq_sizes'] = [m.shape[0] for m in items.values()]\n",
    "    for i in range(len(rawInputData)):\n",
    "        rawInput = rawInputData[i]\n",
    "        user = rawInput['user']\n",
    "        item = rawInput['asin']\n",
    "        matUserInputData.append(users.get(user))\n",
    "        matItemInputData.append(items.get(item))\n",
    "    return matUserInputData, matItemInputData, extra_info\n",
    "\n",
    "def to_key(user, item):\n",
    "    return (user, item)\n",
    "\n",
    "def init_ratings_output_data(rawInputData, input_file, save=False):\n",
    "    ratingsData = []\n",
    "    userItemDict = {}\n",
    "    for i in range(len(rawInputData)):\n",
    "        rawInput = rawInputData[i]\n",
    "        userItem = toKey(rawInput['user'], rawInput['asin'])\n",
    "        userItemDict[userItem] = i\n",
    "        ratingsData.append(None) # check later to make sure no Nones left\n",
    "        \n",
    "    with open(input_file,'r') as f:\n",
    "        for i in f:\n",
    "            line = f.readline()\n",
    "            lineObj = json.loads(line)\n",
    "            user = lineObj['reviewerID']\n",
    "            item = lineObj['asin']\n",
    "            rating = lineObj['overall']\n",
    "            i = userItemDict.get(toKey(user, item))\n",
    "            if i is not None:\n",
    "                ratingsData[i] = rating\n",
    "        failure = None in ratingsData\n",
    "        if failure:\n",
    "            raise ValueError(str(len([r for r in ratingsData if r is None])) + \" reviews did not have corresponding rating.\")\n",
    "    return ratingsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing raw data\n",
      "initializing embeddings\n",
      "initializing vectorized data\n",
      "initializing matrix data\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2c9c102a2780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mall_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_set_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_input_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mvec_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec_output_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_vec_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_output_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmat_user_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat_movie_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_mat_input_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec_output_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/reviews_Amazon_Instant_Video_5.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mratings_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ratings_outputData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-913c11c6dcd6>\u001b[0m in \u001b[0;36minit_mat_input_data\u001b[0;34m(rawInputData, rawOutputData, embedding_map, save)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mvecOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_2_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawOutputData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mrawInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawInputData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawInput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawInput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "fileName = \"data/reviews_Amazon_Instant_Video_5.json\"\n",
    "raw_input_data, raw_output_data = init_raw_data(input_file=fileName)\n",
    "rand_idxs = np.random.permutation(len(raw_output_data))\n",
    "raw_input_data = [raw_input_data[i] for i in rand_idxs]\n",
    "raw_output_data = [raw_output_data[i] for i in rand_idxs]\n",
    "embedding_map = init_embedding_map(\"glove.6B.50d.txt\")\n",
    "all_users = get_set_from_data('user', raw_input_data)\n",
    "all_movies = get_set_from_data('asin', raw_input_data)\n",
    "vec_input_data, vec_output_data = init_vec_data(raw_input_data, raw_output_data, embedding_map)\n",
    "mat_user_input_data, mat_movie_input_data, extra_info = init_mat_input_data(vec_input_data, vec_output_data, embedding_map)\n",
    "file_name = \"data/reviews_Amazon_Instant_Video_5.json\"\n",
    "ratings_data = init_ratings_outputData(raw_input_data, input_file=fileName,save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepCoNN Recommendation Model - Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.merge import Dot\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from keras.layers.merge import Add, Dot, Concatenate\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCoNN():\n",
    "    def __init__(self, embedding_size, hidden_size, u_seq_len, m_seq_len, filters=2, kernel_size=8, strides=6):\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.inputU, self.towerU = self.create_deepconn_tower(u_seq_len)\n",
    "        self.inputM, self.towerM = self.create_deepconn_tower(m_seq_len)\n",
    "        self.joined = Concatenate()([self.towerU, self.towerM])\n",
    "        self.outNeuron = Dense(1)(self.joined)\n",
    "\n",
    "    def create_deepconn_tower(self, max_seq_len):\n",
    "        input_layer = Input(shape=(max_seq_len, self.embedding_size))\n",
    "        tower = Conv1D(filters=self.filters, kernel_size=self.kernel_size, activation=\"relu\")(input_layer)\n",
    "        tower = MaxPooling1D()(tower)\n",
    "        tower = Flatten()(tower)\n",
    "        tower = Dense(self.hidden_size, activation=\"relu\")(tower)\n",
    "        return input_layer, tower\n",
    "\n",
    "    def create_deepconn_dp(self):\n",
    "        dotproduct = Dot(axes=1)([self.towerU, self.towerM])\n",
    "        output = Add()([self.outNeuron, dotproduct])\n",
    "        model = Model(inputs=[self.inputU, self.inputM], outputs=[output])\n",
    "        model.compile(optimizer='Adam', loss='mse')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_DeepcoNN(matUserInputData, matItemInputData, ratingsData, u_seq_len=200, i_seq_len=200, hidden_size=4, epochs=3500, training=None):\n",
    "    embed_dims = matUserInputData[0].shape[1]\n",
    "    deepconn = DeepCoNN(embed_dims, hidden_size, u_seq_len, i_seq_len)\n",
    "\n",
    "    model = deepconn.create_deepconn_dp()\n",
    "\n",
    "    user_input = pad_sequences(np.asarray(matUserInputData), maxlen=u_seq_len)\n",
    "    item_input = pad_sequences(np.asarray(matItemInputData), maxlen=i_seq_len)\n",
    "\n",
    "    trainingN = int(len(user_input) * training) if type(training) is float else training\n",
    "\n",
    "    inputs = [user_input, item_input]\n",
    "    outputs = np.asarray(ratingsData)\n",
    "    print(model.summary())\n",
    "\n",
    "    train_inputs = [user_input[:trainingN], item_input[:trainingN]]\n",
    "    train_outputs = outputs[:trainingN]\n",
    "    test_inputs = [user_input[trainingN:], item_input[trainingN:]]\n",
    "    test_outputs = outputs[trainingN:]\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=4)\n",
    "    early_stopping_val = EarlyStopping(monitor='val_loss', patience=6)\n",
    "    batch_size = 32\n",
    "    history = model.fit(train_inputs, train_outputs, validation_split=0.01, callbacks=[early_stopping, early_stopping_val], batch_size=batch_size, epochs=epochs)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 141, 50)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 474, 50)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 134, 2)       802         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 467, 2)       802         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 67, 2)        0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 233, 2)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 134)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 466)          0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            540         flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            1868        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            9           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1)            0           dense_3[0][0]                    \n",
      "                                                                 dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 4,021\n",
      "Trainable params: 4,021\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 14850 samples, validate on 3713 samples\n",
      "Epoch 1/10\n",
      "14850/14850 [==============================] - 22s 1ms/step - loss: 1.8895 - val_loss: 1.2378\n",
      "Epoch 2/10\n",
      "14850/14850 [==============================] - 22s 2ms/step - loss: 1.2116 - val_loss: 1.2999\n",
      "Epoch 3/10\n",
      "14850/14850 [==============================] - 23s 2ms/step - loss: 1.1330 - val_loss: 1.1231\n",
      "Epoch 4/10\n",
      "14850/14850 [==============================] - 18s 1ms/step - loss: 1.1040 - val_loss: 1.1284\n",
      "Epoch 5/10\n",
      "14850/14850 [==============================] - 17s 1ms/step - loss: 1.0643 - val_loss: 1.1430\n",
      "Epoch 6/10\n",
      "14850/14850 [==============================] - 20s 1ms/step - loss: 1.0546 - val_loss: 1.4243\n",
      "Epoch 7/10\n",
      "14850/14850 [==============================] - 20s 1ms/step - loss: 1.0447 - val_loss: 1.4247\n",
      "Epoch 8/10\n",
      "14850/14850 [==============================] - 20s 1ms/step - loss: 1.0155 - val_loss: 1.1278\n",
      "Epoch 9/10\n",
      "14850/14850 [==============================] - 20s 1ms/step - loss: 0.9967 - val_loss: 1.1256\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 127, 50)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 412, 50)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 120, 2)       802         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 405, 2)       802         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 60, 2)        0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 202, 2)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 120)          0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 404)          0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            484         flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4)            1620        flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8)            0           dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            9           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1)            0           dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1)            0           dense_6[0][0]                    \n",
      "                                                                 dot_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 3,717\n",
      "Trainable params: 3,717\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 14850 samples, validate on 3713 samples\n",
      "Epoch 1/10\n",
      "14850/14850 [==============================] - 16s 1ms/step - loss: 2.2003 - val_loss: 1.2211\n",
      "Epoch 2/10\n",
      "14850/14850 [==============================] - 20s 1ms/step - loss: 1.1969 - val_loss: 1.2029\n",
      "Epoch 3/10\n",
      "14850/14850 [==============================] - 19s 1ms/step - loss: 1.1091 - val_loss: 1.1206\n",
      "Epoch 4/10\n",
      "14850/14850 [==============================] - 17s 1ms/step - loss: 1.0748 - val_loss: 1.1331\n",
      "Epoch 5/10\n",
      "14850/14850 [==============================] - 16s 1ms/step - loss: 1.0294 - val_loss: 1.0779\n",
      "Epoch 6/10\n",
      "14850/14850 [==============================] - 16s 1ms/step - loss: 1.0033 - val_loss: 1.0936\n",
      "Epoch 7/10\n",
      "14850/14850 [==============================] - 17s 1ms/step - loss: 0.9788 - val_loss: 1.0762\n",
      "Epoch 8/10\n",
      "14850/14850 [==============================] - 17s 1ms/step - loss: 0.9794 - val_loss: 1.0841\n",
      "Epoch 9/10\n",
      "14850/14850 [==============================] - 17s 1ms/step - loss: 0.9583 - val_loss: 1.0584\n",
      "Epoch 10/10\n",
      "14850/14850 [==============================] - 16s 1ms/step - loss: 0.9308 - val_loss: 1.1098\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 115, 50)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 351, 50)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 108, 2)       802         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 344, 2)       802         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 54, 2)        0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 172, 2)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 108)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 344)          0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 4)            436         flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            1380        flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8)            0           dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            9           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 1)            0           dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1)            0           dense_9[0][0]                    \n",
      "                                                                 dot_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 3,429\n",
      "Trainable params: 3,429\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 14850 samples, validate on 3713 samples\n",
      "Epoch 1/10\n",
      "14850/14850 [==============================] - 15s 988us/step - loss: 1.7880 - val_loss: 1.2684\n",
      "Epoch 2/10\n",
      "14850/14850 [==============================] - 14s 971us/step - loss: 1.1880 - val_loss: 1.1535\n",
      "Epoch 3/10\n",
      "14850/14850 [==============================] - 15s 984us/step - loss: 1.1306 - val_loss: 1.1724\n",
      "Epoch 4/10\n",
      "14850/14850 [==============================] - 15s 1ms/step - loss: 1.1076 - val_loss: 1.1269\n",
      "Epoch 5/10\n",
      "14850/14850 [==============================] - 17s 1ms/step - loss: 1.0660 - val_loss: 1.1134\n",
      "Epoch 6/10\n",
      "14850/14850 [==============================] - 17s 1ms/step - loss: 1.0527 - val_loss: 1.1516\n",
      "Epoch 7/10\n",
      "14850/14850 [==============================] - 15s 1ms/step - loss: 1.0310 - val_loss: 1.1084\n",
      "Epoch 8/10\n",
      "14850/14850 [==============================] - 15s 1ms/step - loss: 1.0101 - val_loss: 1.1266\n",
      "Epoch 9/10\n",
      "14850/14850 [==============================] - 15s 984us/step - loss: 0.9890 - val_loss: 1.1910\n",
      "Epoch 10/10\n",
      "14850/14850 [==============================] - 15s 1ms/step - loss: 0.9708 - val_loss: 1.1105\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e8b3241f6f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     histories.append(build_DeepcoNN(matUserInputData, matMovieInputData, ratingsData, \n\u001b[1;32m      8\u001b[0m                    \u001b[0mu_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                    epochs=10, training=None))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-8d158d81aa1c>\u001b[0m in \u001b[0;36mbuild_DeepcoNN\u001b[0;34m(matUserInputData, matItemInputData, ratingsData, u_seq_len, i_seq_len, hidden_size, epochs, training)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatUserInputData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mitem_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatItemInputData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrainingN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/deep_learning/venv/lib/python3.6/site-packages/keras/preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calculates median user review length and item length. We then pad each review to these numbers\n",
    "histories = []\n",
    "for i in range(50, 20, -5):\n",
    "    ptile = i\n",
    "    u_seq_len = int(np.percentile(np.array(extra_info['user_seq_sizes']), ptile))\n",
    "    i_seq_len = int(np.percentile(np.array(extra_info['item_seq_sizes']), ptile))\n",
    "    histories.append(build_DeepcoNN(matUserInputData, matMovieInputData, ratingsData, \n",
    "                   u_seq_len=u_seq_len, i_seq_len=i_seq_len, hidden_size=4, \n",
    "                   epochs=10, training=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzDL/H/ZCWsmrhD4eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa806c09748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa8067715f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def graph_loss(loss_arr, title):\n",
    "    plt.scatter(x=range(len(loss)), y=loss)\n",
    "for history in histories:\n",
    "    loss = history.history[\"loss\"]\n",
    "    graph_loss(loss, \"Training Loss\")\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
