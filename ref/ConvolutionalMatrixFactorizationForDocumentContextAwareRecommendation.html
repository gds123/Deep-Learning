<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Convolutaional Matrix Factorization for Document Context-Aware Recommendation">
    <meta name="author" content="Donghyun Kim">

    <title>ConvMF@RecSys'16</title>

    <!-- Bootstrap Core CSS -->
    <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='http://fonts.googleapis.com/css?family=Montserrat:400,700' rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Courgette' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Kalam:400,700,300' rel='stylesheet' type='text/css'>
    <!-- Theme CSS -->
    <link href='../css/ConvMF.css' rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	
	  ga('create', 'UA-85533518-1', 'auto');
	  ga('send', 'pageview');

	</script>
    <nav class="navbar navbar-inverse navbar-custom navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#paper-navbar">
                    <i class="fa fa-bars"></i>
                </button>
                <a class="page-scroll navbar-brand" href="#page-top">ConvMF</a>
            </div>

            <div class="collapse navbar-collapse" id="paper-navbar">
                <ul class="nav navbar-nav navbar-right">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="hidden">
                        <a class="page-scroll" href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#abstract">Abstract</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#overview">Overview</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#experiment">Experiments</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#codedata">Code &amp; Dataset</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="container">
        <div class="row title">
            <div class="col-md-10 col-md-offset-1">
                <h2 class="title-body">Convolutional Matrix Factorization for<br>Document Context-Aware Recommendation</a></h2>
            </div>
        </div>

        <div class="row author">
            <div class="col-md-10 col-md-offset-1">
                <h2 class="author-name"><small><strong>Donghyun Kim</strong><sup>1</sup>, Chanyoung Park<sup>1</sup>, Jinoh Oh<sup>1</sup>, Seungyong Lee<sup>2</sup>, Hwanjo Yu<sup><abbr title="corresponding author">*</abbr>1</sup></small></h2>
                <h3 class="author-aff"><small><sup>1</sup>Pohang University of Science and Technology (POSTECH), Pohang, South Korea
                <br><sup>2</sup>Kyung Hee University, Seoul, South Korea
                <br>
                {<a href="mailto:kdh5377@postech.ac.kr">kdh5377</a>, 
                <a href="mailto:pcy1302@postech.ac.kr">pcy1302</a>, 
                <a href="mailto:kurin@postech.ac.kr">kurin</a>, 
                <a href="mailto:hwanjoyu@postech.ac.kr">hwanjoyu</a>}@postech.ac.kr<sup>1</sup>, 
                <a href="mailto:sylee@oslab.khu.ac.kr">sylee</a>@oslab.khu.ac.kr<sup>2</sup></small></h3>
            </div>
        </div>

        <div id="abstract" class="row abstract content-section">
            <div class="col-md-10 col-md-offset-1">
                <h3>Abstract</h3>
                <hr>
                <p class="abstract-body">Sparseness of user-to-item rating data is one of the major factors that deteriorate the quality of recommender system. To handle the sparsity problem, several recommendation techniques have been proposed that additionally consider auxiliary information to improve rating prediction accuracy. In particular, when rating data is sparse, document modeling-based approaches have improved the accuracy by additionally utilizing textual data such as reviews, abstracts, or synopses. However, due to the inherent limitation of the bag-of-words model, they have difficulties in effectively utilizing contextual information of the documents, which leads to shallow understanding of the documents. This paper proposes a novel context-aware recommendation model, convolutional matrix factorization (ConvMF) that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF). Consequently, ConvMF captures contextual information of documents and further enhances the rating prediction accuracy. Our extensive evaluations on three real-world datasets show that ConvMF significantly outperforms the state-of-the-art recommendation models even when the rating data is extremely sparse. We also demonstrate that ConvMF successfully captures subtle contextual difference of a word in a document.
                </p>
            </div>
        </div>

        <div id="overview" class="row overview content-section">
            <div class="col-md-10 col-md-offset-1">
                <h3>Overview</h3>
                <hr>
                <figure>
                    <img src="../img/ConvMF_PGM_CNN.png" class="img-responsive img-rounded center-block" alt="ConvMF_overview" align="middle">
                    <figcaption>Figure 1. A overview of ConvMF - the left is a probabilistic graphical model of ConvMF which integrates Probabilistic Matrix Factorization (PMF) model and Convolutional Neural Network (CNN) model, and the right is a detailed architecture of the CNN model to utilize item description documents. A document latent vector obtained from the CNN model is used as the mean of Gaussian distribution for the item variable (V) which plays an important role as a bridge between CNN and PMF that helps to fully analyze both description documents and ratings. For more detail, please refer to our <a href="http://dl.acm.org/citation.cfm?id=2959165">paper</a>.</figcaption>
                </figure>
            </div>
        </div>

        <div id="experiment" class="row experiment content-section">
            <div class="col-md-10 col-md-offset-1">
                <h3>Experiments</h3>
                <hr>
                <div class="col-md-12">
                    <h4>Datasets</h4>
                    <p class="subtitle">1. Data Statistics:</p>
                    <div class="table-responsive well well-sm">
                        <table class="table">
                            <thead>
                                <tr>
                                    <th>Dataset</th>
                                    <th># users</th>
                                    <th># items</th>
                                    <th># ratings</th>
                                    <th>density</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>MovieLens-1m (ML-1m)</td>
                                    <td>6,040</td>
                                    <td>3,544</td>
                                    <td>993,482</td>
                                    <td>4.641%</td>
                                </tr>
                                <tr>
                                    <td>MovieLens-10m (ML-10m)</td>
                                    <td>69,878</td>
                                    <td>10,073</td>
                                    <td>9,945,875</td>
                                    <td>1.413%</td>
                                </tr>
                                <tr>
                                    <td>Amazon Instant Video (AIV)</td>
                                    <td>29,757</td>
                                    <td>15,149</td>
                                    <td>135,188</td>
                                    <td>0.030%</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                    <p class="subtitle">2. Data Skewness:</p>
                    <div class="col-sm-6 col-md-6">
                        <figure>
                            <img src="../img/skewness_evidence.png" class="img-responsive img-rounded center-block data_stat" alt="skewness_evidence">
                            <figcaption>Figure 2. Skewness of the number of ratings for items on each dataset</figcaption>
                        </figure>
                    </div>
                    <div class="col-sm-6 col-md-6">
                        <figure>
                            <img src="../img/sparseness_evidence_ab.png" class="img-responsive img-rounded center-block data_stat" alt="sparsensee_evidence">
                            <figcaption>Figure 3. Ratio of items that have less than num. ratings to each entire dataset</figcaption>
                        </figure>
                    </div>
                </div>
                
                <div class="col-md-12">
                    <h4>Competitors</h4>
                    <div class="table-responsive well well-sm">
                        <table class="table">
                            <thead>
                                <tr>
                                    <th>Model</th>
                                    <th>Description</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>Probabilistic Matrix Factorization (PMF)<br>[<a href="https://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf" target="_blank">Salakhutdinov et al.</a>]</td>
                                    <td>A standard rating prediction model that only uses ratings for collaborative filtering.</td>
                                </tr>
                                <tr>
                                    <td>Collaborative Topic Regression (CTR)<br>[<a href="https://dl.acm.org/citation.cfm?id=2020480"target="_blank">Wang et al.</a>]</td>
                                    <td>A state-of-the-art recommendation model that combines collaborative filtering (PMF) and topic modeling (LDA) to use both ratings and documents.</td>
                                </tr>
                                <tr>
                                    <td>Collaborative Deep Learning (CDL)<br>[<a href="https://dl.acm.org/citation.cfm?id=2783273" target="_blank">Wang et al.</a>]</td>
                                    <td>Another state-of-the-art recommendation model that enhances rating prediction accuracy by analyzing documents using stacked denoising auto-encoder (SDAE).</td>
                                </tr>
                                <tr>
                                    <td><b>Convolutional Matrix Factorization (ConvMF)</b></td>
                                    <td><b>Our proposed model.</b></td>
                                </tr>
                                <tr>
                                    <td>Convolutional Matrix Factorization with a pre-trained word embedding model (ConvMF+)</td>
                                    <td>Another version of our proposed model, and we use Glove [<a href="">Pennington et al.</a>] for the pre-trained word embedding model.</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
                <div class="col-md-12">
                    <h4>Results</h4>
                    <h5 style="color: #999; font-weight: 700; border-left: 5px solid #999; padding-left: 10px;">If you want to know more detailed explanation, please refer to our <a href="http://dl.acm.org/citation.cfm?id=2959165">paper</a></h5>
                    <p class="subtitle">1. Overall test RMSE with SD:</p>
                    <div class="table-responsive well well-sm rmse">
                        <table class="table">
                            <thead>
                                <tr>
                                    <th rowspan="2">Model</th>
                                    <th colspan="3">Dataset</th>
                                </tr>
                                <tr>
                                    <th>ML-1m</th>
                                    <th>ML-10m</th>
                                    <th>AIV</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>PMF</td>
                                    <td>0.8971 (0.0020)</td>
                                    <td>0.8311 (0.0010)</td>
                                    <td>1.4118 (0.0105)</td>
                                </tr>
                                <tr>
                                    <td>CTR</td>
                                    <td>0.8969 (0.0027)</td>
                                    <td>0.8275 (0.0004)</td>
                                    <td>1.5496 (0.0104)</td>
                                </tr>
                                <tr>
                                    <td>CDL</td>
                                    <td>0.8879 (0.0015)</td>
                                    <td>0.8186 (0.0005)</td>
                                    <td>1.3594 (0.0139)</td>
                                </tr>
                                <tr style="font-weight: bold; color: #337ab7">
                                    <td>ConvMF</td>
                                    <td>0.8531 (0.0018)</td>
                                    <td>0.7958 (0.0006)</td>
                                    <td>1.1337 (0.0043)</td>
                                </tr>
                            </tbody>
                            <thead>
                                <tr style="font-weight: bold; color: #337ab7">
                                    <th>ConvMF+</th>
                                    <th>0.8549 (0.0018)</th>
                                    <th>0.7930 (0.0006)</th>
                                    <th>1.1279 (0.0073)</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr style="font-weight: bold;">
                                    <td>Improve</td>
                                    <td>3.92%</td>
                                    <td>2.79%</td>
                                    <td>16.60%</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                    <blockquote>
                        <p>Above table shows the overall rating prediction errors of five methods on each test set. Note that each dataset is randomly split into a training set (80%), a validation set (10%), and a test set (10%). "Improve" indicates the relative improvements of "ConvMF" over the the best competitor. Compared to three models, <b>ConvMF and ConvMF+ achieve significant improvements on all the datasets.</b></p>
                    </blockquote>
                    <p class="subtitle">2. Test RMSE over various sparseness of training data on ML-1m dataset:</p>
                    <figure>
                        <img src="../img/Sparseness_Plot.png" class="img-responsive img-rounded center-block various_sparse" alt="Sparsensee_Result">
                    </figure>
                    <blockquote>
                        <p>This plot shows improvements of ConvMF on three competitors over various spaseness datasets. ConvMF significantly outperforms three competitors over all range over sparseness, and we can see that when the data density increases, the improvements increase. It indicates that <b>CNN of ConvMF is well integrated into PMF for recommendation task to exploit rating information</b>.</p>
                    </blockquote>
                    <p class="subtitle">3. Impact of Pre-trained Word Embedding Model:</p>
                    <div class="col-sm-6 col-md-6">
                        <figure>
                            <img src="../img/embedding_lambda_plot.png" class="img-responsive img-rounded center-block embedding_plot" alt="impact_embedding_model" width="90%">
                        </figure>
                    </div>
                    <div class="col-sm-6 col-md-6">
                        <figure>
                            <img src="../img/embedding_plot_2.png" class="img-responsive img-rounded center-block embedding_plot" alt="anal_size_embedding_model" width="90%">
                        </figure>
                    </div>
                    <div class="row">
                    </div>
                    <blockquote>
                        <p>Two plots introduce impacts of pre-trained word embedding model for ConvMF. Left plot shows relative improvements of ConvMF+ over ConvMF on three datasets with various &lambda;<sub>v</sub>. <b>As data is more extremely skewed (i.e. Amazon Instant Video), an impact of pre-trained word embedding model increases</b>. Note that a high value of &lambda;<sub>v</sub> leads that ConvMF and ConvMF+ try to exploit description documents of items more than ratings. Right plot shows the effects of the dimension size of word embedding model on Amazon Instant Video dataset. <b>The test error of ConvMF+ is decreased as the dimension size of the pre-trained word embedding model gets higher</b>, because the information contained in the model gets richer.</p>
                    </blockquote>
                    <p class="subtitle">4. Parameter Analysis:</p>
                    <div class="col-sm-4 col-md-4">
                        <figure>
                            <img src="../img/movielens_1m_reg_anal.png" class="img-responsive img-rounded center-block lambda_plot" alt="anal_lambda_ml-1m">
                            <figcaption style="text-align: center;">MovieLens-1m</figcaption>
                        </figure>
                    </div>
                    <div class="col-sm-4 col-md-4">
                        <figure>
                            <img src="../img/movielens_10m_reg_anal.png" class="img-responsive img-rounded center-block lambda_plot" alt="anal_lambda_ml-10m">
                            <figcaption style="text-align: center;">MovieLens-10m</figcaption>
                        </figure>
                    </div>
                    <div class="col-sm-4 col-md-4">
                        <figure>
                            <img src="../img/amazon_reg_anal.png" class="img-responsive img-rounded center-block lambda_plot" alt="anal_lambda_amazon">
                            <figcaption style="text-align: center;">Amazon Instant Video</figcaption>
                        </figure>
                    </div>
                    <div class="row">
                    </div>
                    <blockquote>
                        <p>Three figures shows impacts of &lambda;<sub>u</sub> and &lambda;<sub>v</sub> on three datasets. Specifically, the best performing values of (&lambda;<sub>u</sub>, &lambda;<sub>v</sub>) of ConvMF are (100, 10), (10, 100), and (1, 100) on MovieLens-1m, MovieLens-10m and Amazon Instant Video, respectively. A high value of &lambda;<sub>u</sub> implies that item latnet model tend to be projeted to the latent space of user latent model (same applies to &lambda;<sub>v</sub>). <b>Thus, these best performing values demonstrate that ConvMF well alleviates sparseness of each dataset by balancing the importance of ratings and description documents</b>. Note that a sparse dataset requires high value of &lambda;<sub>v</sub>.</p>
                    </blockquote>
                    <p class="subtitle">5. Qualitative Analysis:</p>
                    <div class="qual_anal">
                        <div class="table-responsive">
                            <table class="table table-bordered table-condensed">
                                <thead>
                                    <tr style="background-color: #bbb">
                                        <th>Phrase captured by W<sub>c</sub><sup>11</sup></th>
                                        <th>max(c<sup>11</sup>)</th>
                                        <th>Phrase captured by W<sub>c</sub><sup>86</sup></th>
                                        <th>max(c<sup>86</sup>)</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>people <b>trust</b> <span style="color: gray">the</span> man</td>
                                        <td><b>0.0704</b></td>
                                        <td>betray <span style="color: gray">his</span> <b>trust</b> finally</td>
                                        <td><b>0.1009</b></td>
                                    </tr>
                                </tbody>
                                <thead>
                                    <tr style="background-color: #bbb">
                                        <th>Test phrases for W<sub>c</sub><sup>11</sup></th>
                                        <th>max(c<sub>test</sub><sup>11</sup>)</th>
                                        <th>Test phrases for W<sub>c</sub><sup>86</sup></th>
                                        <th>max(c<sub>test</sub><sup>86</sup>)</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>people <b>believe</b> <span style="color: gray">the</span> man</td>
                                        <td style="color: #337ab7"><b>0.0391</b></td>
                                        <td>betray <span style="color: gray">his</span> <b>believe</b> finally</td>
                                        <td>0.0682</td>
                                    </tr>
                                    <tr>
                                        <td>people <b>faith</b> <span style="color: gray">the</span> man</td>
                                        <td>0.0374</td>
                                        <td>betray <span style="color: gray">his</span> <b>faith</b> finally</td>
                                        <td style="color: #337ab7"><b>0.0693</b></td>
                                    </tr>
                                    <tr>
                                        <td>people <b>tomas</b> <span style="color: gray">the</span> man</td>
                                        <td>0.0054</td>
                                        <td>betray <span style="color: gray">his</span> <b>tomas</b> finally</td>
                                        <td>0.0480</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>
                    <blockquote>
                        <p>This table verifies whether ConvMF is able to distinguish subtle contextual differences by comparing each contextual meanings of phrases captured by the shared weights of CNN. Specifically, as a case study, we selected W<sub>c</sub><sup>11</sup> and W<sub>c</sub><sup>86</sup> from the model trained on ML-10m dataset, and compared the contextual meaning of phrases captured by the shared weights. The meaning of “trust” in the two phrases captured by the two shared weights seem to be similar to each other. However, there is a subtle difference on contextual meaning of the term “trust” in the two phrases. Indeed, the “trust” in the phrase captured by W<sub>c</sub><sup>11</sup> is used as a verb whereas the “trust” in the phrase captured by W<sub>c</sub><sup>86</sup> is used as a noun. A higher context feature value has more chance to be selected in order to affect the performance of ConvMF, and we can see that <b>ConvMF distinguishes a subtle contextual difference of the term "trust"</b>.</p>
                    </blockquote>
                </div>
            </div>
        </div>
        <div id="codedata" class="row content-section">
            <div class="col-md-10 col-md-offset-1">
                <h3>Code & Data</h3>
                <hr>
				<ul>
					<li>Our code is <a href="https://github.com/cartopy/ConvMF-1.0.0.git">here [Github]</a>.</li>
					<li>Datasets [<i>MovieLens and Amazon Instant Video</i>] are <a href="./data/">here</a>.</li>
				</ul>
            </div>
        </div>
    </div>

    <footer>
        <div class="container text-center">
            <div class="row">
                <p>&copy; 2016 <strong>Donghyun Kim</strong></p>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="../vendor/jquery/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="../vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>

    <!-- Theme JavaScript -->
    <script src="../js/grayscale.min.js"></script>

</body>
