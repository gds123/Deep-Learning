% !TEX program = pdflatex
\documentclass[preprint,10.5pt]{article}

\usepackage{listings}
\usepackage{tasks}
\usepackage{graphicx}
\usepackage{hyperref}

\pagenumbering{gobble}

\usepackage[                                                                       
 paper  = letterpaper,                                                            
 left   = 1.0in,                                                                 
 right  = 1.0in,                                                                 
 top    = 0.5in,                                                                  
 bottom = 0.5in,                                                                  
 ]{geometry}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=purple,
}

\begin{document}

\title{Deep Learning $|$ Final Project Proposal}
\author{Michael Alvarino (maa2282), Richard Dewey (rld2126), Colby Wise (cjw2165)}

\maketitle

\section{Project Overview} 
\paragraph{One-liner} We intend to build a movie recommendation system that will jointly model users and movies by combining collaborative filtering techniques with deep learning via wide and deep convolutional neural network ($CNN$) and recurrent neural network ($RNN$) architectures.

\paragraph{The Problem} Prior to deep learning, standard approaches for recommendation systems ($RecSys$) used collaborative filtering ($CF$) which relies on decomposing users, items (i.e. movies), and ratings into latent feature matrices. Then the weights of these matrices are used to predict a rating a user would give for an item. These approaches suffer from sparsity which pushed recent research to use review data posted by users to reduce sparsity and improve prediction accuracy. Given accuracy improvements in text modeling from deep learning via CNN/RNN recent RecSys research has focused on combining CF with deep learning. Our project will reference such research to build a movie recommendation system utilizing the follow datasets. 

\paragraph{Data} We intend to use one primary open source dataset, the Amazon Instant Video ($AIV$). In addition there are three open source datasets, $MovieLens$, $Netflix$, and $IMDB$ which have overlap in movies and ratings, but distinct features, making them part of a complimentary set. Should the possibility present itself we would also like to include the YouTube 8m dataset, specifically videos whose name or description includes the title of a film in question, which could provide additional data not captured by reviews and ratings like the color schemes and quality of editing of the film.

\paragraph{Previous Work and References} The literature on recommendation systems is deep. We plan to focus on the following five papers which all offer similar approaches to incorporating review data while jointly modeling users/items with CF and DL in RecSys.\\
\ \newline
\href{https://arxiv.org/pdf/1701.04783.pdf}{Joint Deep Modeling of Users and Items Using Reviews for Recommendation}\\
\ \newline
\href{https://arxiv.org/pdf/1703.04247.pdf}{DeepFM: A Factorization-Machine based Neural Network for CTR Prediction}\\
\ \newline
\href{https://cs224d.stanford.edu/reports/BalakrishnanDixit.pdf}{DeepPlaylist: Using Recurrent Neural Networks to
Predict Song Similarity}\\
\ \newline
\href{https://www.tensorflow.org/tutorials/wide_and_deep}{TensorFlow Tutorial: Wide \& Deep Learning}\\
\ \newline
\href{http://dm.postech.ac.kr/~cartopy/ConvMF/}{Convolutional Matrix Factorization for Document Context-Aware Recommendation}

\paragraph{Sample Model} We intend to build a model to learn item properties and user behaviors jointly from review text using two parallel neural networks, coupled at a final layer. In addition we will append the result of this network to a wide network, similar to that of Google's Wide and Deep network, to improve the final predicted user ratings of movies.

\paragraph{Evaluation Criteria} Standard practice in RecSys modeling is to evaluate new models against standard collaborative filtering techniques and against more recent deep learning models with similar parameters. To quantify results researchers use \href{https://en.wikipedia.org/wiki/Receiver_operating_characteristic}{Area Under the ROC Curve }, cross entropy loss, or Mean-Squared Error ($MSE$) on train/test data. They compare this across the models described above. Additionally, some papers will compare models with different parameter settings (optimizer, CNN layers, regularization). We will use one or more of these approaches combined with visualizations like weight gradient and accuracy plots, and provide sample test cases.  




\end{document}