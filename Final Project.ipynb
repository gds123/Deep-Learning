{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO List\n",
    "1. Move the data loading functions to another file that we can import\n",
    "1. The data is sorted, needs to be shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = {i[i.find('/') + 1:]: i for i in [\"product/productId\",\n",
    "                                         \"review/userId\",\n",
    "                                         \"review/profileName\",\n",
    "                                         \"review/helpfulness\",\n",
    "                                         \"review/score\",\n",
    "                                         \"review/time\",\n",
    "                                         \"review/summary\",\n",
    "                                         \"review/text\"]}\n",
    "\n",
    "\n",
    "def parse(filename):\n",
    "    f = gzip.open(filename, 'r')\n",
    "    entry = {}\n",
    "    for l in f:\n",
    "        l = str(l.strip())\n",
    "        colonPos = l.find(':')\n",
    "        if colonPos == -1:\n",
    "            yield entry\n",
    "            entry = {}\n",
    "            continue\n",
    "        eName = l[:colonPos][2:]\n",
    "        rest = l[colonPos + 2:-1]\n",
    "        entry[eName] = rest\n",
    "    yield entry\n",
    "\n",
    "\n",
    "def get_n_reviews(filename, num_reviews):\n",
    "    gen = parse(filename)\n",
    "    results = []\n",
    "    for i in range(num_reviews):\n",
    "        results.append(next(gen))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(object):\n",
    "    def __init__(self, data, test_fraction):\n",
    "        train_fraction = 1 - test_fraction\n",
    "        self.data_size = len(data)\n",
    "        train_indices = np.random.choice(self.data_size,\n",
    "                                         int(self.data_size * train_fraction),\n",
    "                                         replace=False)\n",
    "        # thank god this works... i did NOT feel like converting json to a dataframe...\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # convert user ids to integers\n",
    "        self.user_ids = df[keys[\"userId\"]].unique()\n",
    "        self.numbers_to_product_ids = {i: j for i, j in zip(range(len(self.user_ids)), self.user_ids)}\n",
    "        self.user_ids_to_numbers = {j: i for i, j in self.numbers_to_product_ids.items()}\n",
    "        self.num_user_ids = len(self.user_ids_to_numbers)\n",
    "        \n",
    "        # convert product ids to integers\n",
    "        self.product_ids = df[keys[\"productId\"]].unique()\n",
    "        self.numbers_to_product_ids = {i: j for i, j in zip(range(len(self.product_ids)), self.product_ids)}\n",
    "        self.product_ids_to_numbers = {j: i for i, j in self.numbers_to_product_ids.items()}\n",
    "        self.num_product_ids = len(self.product_ids_to_numbers)\n",
    "        \n",
    "        # convert profileName to integer (not running any embedding on profile name, only on the review)\n",
    "        self.profile_names = df[keys[\"profileName\"]].unique()\n",
    "        self.numbers_to_profile_names = {i: j for i, j in zip(range(len(self.profile_names)), self.profile_names)}\n",
    "        self.profile_names_to_numbers = {j: i for i, j in self.numbers_to_profile_names.items()}\n",
    "        self.num_profile_names = len(self.profile_names_to_numbers)\n",
    "        \n",
    "        # user-review matrix.\n",
    "        self.user_score = np.zeros((self.num_user_ids, self.num_product_ids))\n",
    "        for idx, row in df.iterrows():\n",
    "            self.user_score[idx, self.product_ids_to_numbers[row[keys[\"productId\"]]]] = row[keys[\"score\"]]\n",
    "        \n",
    "        # this might be useful later when we implement the text-analysis version\n",
    "        self.user_text = {}\n",
    "        self.product_text = {}\n",
    "        for idx, review in df.iterrows():\n",
    "            text = review[keys[\"text\"]]\n",
    "            try:\n",
    "                self.user_text[review[keys[\"userId\"]]].append(text)\n",
    "            except:\n",
    "                self.user_text[review[keys[\"userId\"]]] = [text]\n",
    "            try:\n",
    "                self.product_text[review[keys[\"productId\"]]].append(text)\n",
    "            except:\n",
    "                self.product_text[review[keys[\"productId\"]]] = [text]\n",
    "    \n",
    "    def define_feature_columns():\n",
    "        helpfulness = tf.feature_column.numeric_column(\"review/helpfulness\")\n",
    "        user_id = tf.feature_column.categorical_column_with_identity(\"review/userId\",\n",
    "                                                                     num_buckets=self.num_user_ids)\n",
    "        product_id = tf.feature_column.categorical_column_with_identity(\"product/productId\",\n",
    "                                                                        num_buckets=self.num_product_ids)\n",
    "        profile_name = tf.feature_column.categorical_column_with_identity(\"review/profileName\",\n",
    "                                                                         num_buckets=self.num_profile_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 3.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 5.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 3.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 3.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 2.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  4.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  4.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  5.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  3.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  4.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  3.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  4.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  5.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  3.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  5.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  4.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  4.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  5.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  4.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  5.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  3.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  4.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  5.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  5.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  5.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  4.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  5.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  3.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  4.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  5.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  4.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  5.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  5.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  5.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  5.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  5.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  5.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  5.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  5.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  4.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  5.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  4.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  4.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  3.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  4.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  4.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  4.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  3.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  3.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  4.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  4.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  5.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wad = WideAndDeep(get_n_reviews(\"data/movies.txt.gz\", 100), 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
