{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import simplejson\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_input_data(path_to_data='data/reviews_Amazon_Instant_Video_5.json', save=False):\n",
    "    print('Aggregating all the review text')\n",
    "    rawData = []\n",
    "    with open(path_to_data,'r') as f:\n",
    "        for i in f:\n",
    "            line = f.readline()\n",
    "            lineObj = json.loads(line)\n",
    "            user = lineObj['reviewerID']\n",
    "            movie = lineObj['asin']\n",
    "            rating = lineObj['overall']\n",
    "            review = lineObj['reviewText']\n",
    "            rawInputDataObj = {'user':user, 'movieID':movie, 'rating':rating, 'review':review}\n",
    "            rawData.append(rawInputDataObj)\n",
    "            \n",
    "    if save:\n",
    "        pickle.dump((rawData), open('raw_input_data.pkl','wb'))\n",
    "    return rawData\n",
    "\n",
    "def get_model_data(inputData):\n",
    "    users = {}\n",
    "    movies = {}\n",
    "    users_and_reviews = {}\n",
    "    movies_and_reviews = {}\n",
    "    for item in inputData:\n",
    "        user = item['user']\n",
    "        movie = item['movieID']\n",
    "        review = item['review']\n",
    "        users.setdefault(user, []).append(movie)\n",
    "        movies.setdefault(movie, []).append(user)\n",
    "        users_and_reviews.setdefault(user, []).append(review)\n",
    "        movies_and_reviews.setdefault(movie, []).append(review)\n",
    "    return (users, movies, users_and_reviews,movies_and_reviews)\n",
    "\n",
    "def aggregate_all_reviews(path_to_data='data/reviews_Amazon_Instant_Video_5.json', save=False):\n",
    "    print('Aggregating all the review text')\n",
    "    rawReviewData = []\n",
    "    with open(path_to_data,'r') as f:\n",
    "        for i in f:\n",
    "            line = f.readline()\n",
    "            lineObj = json.loads(line)\n",
    "            review = lineObj['reviewText']\n",
    "            rawReviewData.append(review)\n",
    "            \n",
    "    if save:\n",
    "        pickle.dump((rawReviewData), open('agg_review_data.pkl','wb'))\n",
    "    return rawReviewData\n",
    "\n",
    "def build_vocab(agg_text, word_len=250, vocab_size=25000):\n",
    "    #length of vocab, Tokenizer will only use vocab_len most common words\n",
    "    print(\"Length of vocabulary: \", vocab_size)\n",
    "\n",
    "    #we tokenize the texts and convert all the words to tokens\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(agg_text)\n",
    "    print(\"Fitting and returning tokenizer object\")\n",
    "    return tokenizer\n",
    "\n",
    "def tokenize_reviews(data, tokenizer, word_len=250):\n",
    "    #clip the sentence length to first (word_len) words.\n",
    "    print(\"Max word length: \", word_len)\n",
    "    # Default text_to_sq removes punc,lowercases, + splits\" \"\n",
    "    token_data = tokenizer.texts_to_sequences(data) #No filters, lowercase, not sure which is better\n",
    "    \n",
    "    #Ensure all reviews have the same length, we pad the smaller reviews with 0, \n",
    "    #and cut the larger reviews to a max length \n",
    "    #(we clip from the top, as the end of the reviews generally have a conclusion which provides better features)\n",
    "    print(\"Padding sequences and returning sequence\")\n",
    "    return sequence.pad_sequences(token_data, maxlen=word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating all the review text\n",
      "Length of vocabulary:  25000\n",
      "Fitting and returning tokenizer object\n",
      "Max word length:  250\n",
      "Padding sequences and returning sequence\n"
     ]
    }
   ],
   "source": [
    "path_to_data = 'data/reviews_Amazon_Instant_Video_5.json'\n",
    "review_data = aggregate_all_reviews(path_to_data)\n",
    "tokenizer = build_vocab(review_data)\n",
    "tokenized_reviews = tokenize_reviews(review_data, tokenizer, word_len=250)\n",
    "#print(\"tokenized_reviews:\\n\", tokenized_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample review:\n",
      " I highly recommend this series. It is a must for anyone who is yearning to watch \"grown up\" television. Complex characters and plots to keep one totally involved. Thank you Amazin Prime.\n",
      "Max word length:  250\n",
      "Padding sequences and returning sequence\n",
      "\n",
      "Padded tokenized review:\n",
      " [[   0    0    0 ...,    0    0    7]\n",
      " [   0    0    0 ...,    0    0    0]\n",
      " [   0    0    0 ...,    0    0 1593]\n",
      " ..., \n",
      " [   0    0    0 ...,    0    0 1673]\n",
      " [   0    0    0 ...,    0    0  852]\n",
      " [   0    0    0 ...,    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "sample_review = review_data[0]\n",
    "print(\"Sample review:\\n\", sample_review)\n",
    "tokens = tokenize_reviews(sample_review, tokenizer, word_len=250)\n",
    "print(\"\\nPadded tokenized review:\\n\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating all the review text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'movieID': 'B000H00VBQ',\n",
       "  'rating': 5.0,\n",
       "  'review': 'I highly recommend this series. It is a must for anyone who is yearning to watch \"grown up\" television. Complex characters and plots to keep one totally involved. Thank you Amazin Prime.',\n",
       "  'user': 'A3BC8O2KCL29V2'},\n",
       " {'movieID': 'B000H00VBQ',\n",
       "  'rating': 4.0,\n",
       "  'review': 'Mysteries are interesting.  The tension between Robson and the tall blond is good but not always believable.  She often seemed uncomfortable.',\n",
       "  'user': 'A1RJPIGRSNX4PW'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Returns aggregated raw data where each entry in list is dictionary of a unique (user, review, rating, movie)\n",
    "So user can show up multiple times in list but not for same review/movie\n",
    "\"\"\"\n",
    "raw_data = get_raw_input_data()\n",
    "raw_data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns lists of dictionaries \n",
    "user_data: users and list of moviesIDs they reviewed\n",
    "movie_data: movies with userIDs of users who have rated them\n",
    "user_to_reviews: (*important*) users with their reviews\n",
    "movie_to_reviews: (*important*) movies with their reviews\n",
    "\"\"\"\n",
    "user_data, movie_data, user_to_reviews, movie_to_reviews = get_model_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I highly recommend this series. It is a must for anyone who is yearning to watch \"grown up\" television. Complex characters and plots to keep one totally involved. Thank you Amazin Prime.', \"I watched this film on Saturday and it is now Wednesday and I am stilling thinking about it. This is an Australian film, so the pace of the story is somewhat different...the crescendos are quieter but the sentinel events are clear. The film explores the boundaries of  a friendship and what liberties are accepted and why. Both Naomi Watts and Robin Wright give performances which ring true and are compelling.  The young male leads are also quite strong. It's good and surprising story telling.\", \"I was not sure what I was getting but this film kept me watching. I was curious about. Each character's history and and motivation. The acting was good and there were familiar faces sprinkled throughout. I continue to be curious web out what comes next. All in all, I think this is a well written and well acted drama and there are probably surprises. Watch it and see what you think!\"]\n",
      "\n",
      "['If I had a friend Like MacGyver, than I would have try Survival Island and we would win all the money.', 'It was  Good and funny I enjoy it it is worth watching a family movie Just enjoy  very light  Enjoy', \"James Bond minus the adult stuff.  Great show that shows the mind is still the best weapon.  Sure there is some liberal stuff thrown in but it is family friendly.  And who can't resist the MacGyverisms as you think could that work.  Maybe not but it will make the kids think and want to experiment.  Good stuff for the whole family.\"]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "If you run the entire thing you may/will get IO warning (requires alot of memory to print)\n",
    "Here's one example of a user's reviews before Encoding!\n",
    "\"\"\"\n",
    "print(user_to_reviews['A3BC8O2KCL29V2']) #A3BC8O2KCL29V2 #A1RJPIGRSNX4PW\n",
    "print()\n",
    "# Example of a movie's reviews\n",
    "print(movie_to_reviews['B000HKWE3O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_tf",
   "language": "python",
   "name": "dl_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
